{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49e07a3078194f8f8c2187ceb252788d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f39b9ea7764d4a83bf37adaef3f57097",
              "IPY_MODEL_a141d7762ded4914a49b5b17dff21779",
              "IPY_MODEL_0bbe962f917b45dfb7e045f75e89dec9"
            ],
            "layout": "IPY_MODEL_2875dac9d4b047d9ba0e66d46ee1aa13"
          }
        },
        "f39b9ea7764d4a83bf37adaef3f57097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ae0faead11341b1bcbac938f2dd4736",
            "placeholder": "​",
            "style": "IPY_MODEL_7df47a181cd04781b0df1c03c7f6b437",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a141d7762ded4914a49b5b17dff21779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc737d9c8a84486aa1dbb30490536b6b",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00a07cdeded442a796966b0c30a043bf",
            "value": 7
          }
        },
        "0bbe962f917b45dfb7e045f75e89dec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754003296e3e43b8a915cdf36721f029",
            "placeholder": "​",
            "style": "IPY_MODEL_da9737300f5546a28906a3cf66be2432",
            "value": " 7/7 [00:02&lt;00:00,  2.53it/s]"
          }
        },
        "2875dac9d4b047d9ba0e66d46ee1aa13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae0faead11341b1bcbac938f2dd4736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df47a181cd04781b0df1c03c7f6b437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc737d9c8a84486aa1dbb30490536b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a07cdeded442a796966b0c30a043bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "754003296e3e43b8a915cdf36721f029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9737300f5546a28906a3cf66be2432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMZ-PRH7q0YA",
        "outputId": "0f78bacf-ca71-44df-cd4d-8d95b06c4b10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChatGLM3'...\n",
            "remote: Enumerating objects: 1316, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 1316 (delta 2), reused 11 (delta 1), pack-reused 1300\u001b[K\n",
            "Receiving objects: 100% (1316/1316), 17.36 MiB | 35.06 MiB/s, done.\n",
            "Resolving deltas: 100% (742/742), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/THUDM/ChatGLM3.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ40wmdNrEpF",
        "outputId": "d1b08a7f-fd08-461e-ba05-3b8f3ddb4355"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8.0K\n",
            "drwxr-xr-x 13 root root 4.0K Apr  7 14:02 ChatGLM3\n",
            "drwxr-xr-x  1 root root 4.0K Apr  4 13:24 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ChatGLM3 && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp-FSkU9rHrQ",
        "outputId": "b9195e01-f44e-47e4-86a7-53c0d84efe5d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf>=4.25.3 (from -r requirements.txt (line 3))\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.38.2)\n",
            "Requirement already satisfied: tokenizers>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.15.2)\n",
            "Collecting cpm_kernels>=1.0.11 (from -r requirements.txt (line 6))\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.2.1+cu121)\n",
            "Collecting gradio>=4.19.2 (from -r requirements.txt (line 8))\n",
            "  Downloading gradio-4.25.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.2.0 (from -r requirements.txt (line 9))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers>=2.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.27.2 (from -r requirements.txt (line 11))\n",
            "  Downloading accelerate-0.29.1-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.3/297.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit>=1.31.0 (from -r requirements.txt (line 12))\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.109.0 (from -r requirements.txt (line 13))\n",
            "  Downloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru~=0.7.2 (from -r requirements.txt (line 14))\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdtex2html>=1.3.0 (from -r requirements.txt (line 15))\n",
            "  Downloading mdtex2html-1.3.0-py3-none-any.whl (13 kB)\n",
            "Collecting latex2mathml>=3.77.0 (from -r requirements.txt (line 16))\n",
            "  Downloading latex2mathml-3.77.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_client>=8.6.0 (from -r requirements.txt (line 17))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.12.0 (from -r requirements.txt (line 20))\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zhipuai>=2.0.1 (from -r requirements.txt (line 21))\n",
            "  Downloading zhipuai-2.0.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pydantic>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (2.6.4)\n",
            "Collecting sse-starlette>=2.0.0 (from -r requirements.txt (line 24))\n",
            "  Downloading sse_starlette-2.1.0-py3-none-any.whl (9.2 kB)\n",
            "Collecting uvicorn>=0.27.1 (from -r requirements.txt (line 25))\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm>=0.9.12 (from -r requirements.txt (line 26))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken>=0.6.0 (from -r requirements.txt (line 27))\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain>=0.1.9 (from -r requirements.txt (line 31))\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub>=0.1.14 (from -r requirements.txt (line 32))\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Collecting arxiv>=2.1.0 (from -r requirements.txt (line 33))\n",
            "  Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.1->-r requirements.txt (line 4)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->-r requirements.txt (line 7)) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (4.2.2)\n",
            "Collecting ffmpy (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.15.0 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading gradio_client-0.15.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (6.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (9.4.0)\n",
            "Collecting pydub (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading ruff-0.3.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.19.2->-r requirements.txt (line 8)) (0.9.4)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.15.0->gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers>=2.4.0->-r requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers>=2.4.0->-r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.27.2->-r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (8.1.7)\n",
            "Collecting protobuf>=4.25.3 (from -r requirements.txt (line 3))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (14.0.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (0.10.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit>=1.31.0->-r requirements.txt (line 12))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit>=1.31.0->-r requirements.txt (line 12))\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.31.0->-r requirements.txt (line 12)) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit>=1.31.0->-r requirements.txt (line 12))\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.109.0->-r requirements.txt (line 13))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mdtex2html>=1.3.0->-r requirements.txt (line 15)) (3.6)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.0->-r requirements.txt (line 17)) (5.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.0->-r requirements.txt (line 17)) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.0->-r requirements.txt (line 17)) (23.2.1)\n",
            "Requirement already satisfied: traitlets>=5.3 in /usr/local/lib/python3.10/dist-packages (from jupyter_client>=8.6.0->-r requirements.txt (line 17)) (5.7.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.12.0->-r requirements.txt (line 20)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.12.0->-r requirements.txt (line 20)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.12.0->-r requirements.txt (line 20)) (1.3.1)\n",
            "Collecting pyjwt~=2.8.0 (from zhipuai>=2.0.1->-r requirements.txt (line 21))\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.6.2->-r requirements.txt (line 23)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.6.2->-r requirements.txt (line 23)) (2.16.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.27.1->-r requirements.txt (line 25))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.12->-r requirements.txt (line 26)) (0.17.1+cu121)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.9->-r requirements.txt (line 31)) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.9->-r requirements.txt (line 31)) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.1.9->-r requirements.txt (line 31)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub>=0.1.14->-r requirements.txt (line 32))\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Collecting feedparser==6.0.10 (from arxiv>=2.1.0->-r requirements.txt (line 33))\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sgmllib3k (from feedparser==6.0.10->arxiv>=2.1.0->-r requirements.txt (line 33))\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.1->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.1->-r requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.1->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.38.1->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.9->-r requirements.txt (line 31)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.9->-r requirements.txt (line 31)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.9->-r requirements.txt (line 31)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.9->-r requirements.txt (line 31)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.9->-r requirements.txt (line 31)) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.12.0->-r requirements.txt (line 20)) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.31.0->-r requirements.txt (line 12))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter_client>=8.6.0->-r requirements.txt (line 17)) (4.2.0)\n",
            "Collecting packaging>=20.0 (from transformers>=4.38.1->-r requirements.txt (line 4))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.19.2->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.19.2->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.19.2->-r requirements.txt (line 8)) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.19.2->-r requirements.txt (line 8)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio>=4.19.2->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.19.2->-r requirements.txt (line 8)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio>=4.19.2->-r requirements.txt (line 8)) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter_client>=8.6.0->-r requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.31.0->-r requirements.txt (line 12)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=1.31.0->-r requirements.txt (line 12)) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.9->-r requirements.txt (line 31)) (3.0.3)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio>=4.19.2->-r requirements.txt (line 8))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers>=2.4.0->-r requirements.txt (line 10)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers>=2.4.0->-r requirements.txt (line 10)) (3.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->-r requirements.txt (line 7)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.31.0->-r requirements.txt (line 12))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio>=4.19.2->-r requirements.txt (line 8)) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.31.0->-r requirements.txt (line 12)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.1.9->-r requirements.txt (line 31))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: ffmpy, sgmllib3k\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=da3f511d21d7b7812af9911213d9f54902599e91f4ad798a52585ebb5e97ced5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=09e96f4f3a572d930be2c13c7f64503883ac28098a34856117de8bcd929de912\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built ffmpy sgmllib3k\n",
            "Installing collected packages: sgmllib3k, sentencepiece, pydub, ffmpy, cpm_kernels, websockets, watchdog, types-requests, tomlkit, smmap, shellingham, semantic-version, ruff, python-multipart, pyjwt, protobuf, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, loguru, latex2mathml, jsonpointer, h11, feedparser, colorama, aiofiles, uvicorn, typing-inspect, tiktoken, starlette, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mdtex2html, marshmallow, langchainhub, jupyter_client, jsonpatch, httpcore, gitdb, arxiv, sse-starlette, nvidia-cusolver-cu12, langsmith, httpx, gitpython, fastapi, dataclasses-json, zhipuai, openai, langchain-core, gradio-client, streamlit, sentence_transformers, langchain-text-splitters, langchain-community, gradio, accelerate, timm, langchain\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: jupyter_client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.29.1 aiofiles-23.2.1 arxiv-2.1.0 colorama-0.4.6 cpm_kernels-1.0.11 dataclasses-json-0.6.4 fastapi-0.110.1 feedparser-6.0.10 ffmpy-0.3.2 gitdb-4.0.11 gitpython-3.1.43 gradio-4.25.0 gradio-client-0.15.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 jupyter_client-8.6.1 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-text-splitters-0.0.1 langchainhub-0.1.15 langsmith-0.1.40 latex2mathml-3.77.0 loguru-0.7.2 marshmallow-3.21.1 mdtex2html-1.3.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 openai-1.16.2 orjson-3.10.0 packaging-23.2 protobuf-4.25.3 pydeck-0.8.1b0 pydub-0.25.1 pyjwt-2.8.0 python-multipart-0.0.9 ruff-0.3.5 semantic-version-2.10.0 sentence_transformers-2.6.1 sentencepiece-0.2.0 sgmllib3k-1.0.0 shellingham-1.5.4 smmap-5.0.1 sse-starlette-2.1.0 starlette-0.37.2 streamlit-1.33.0 tiktoken-0.6.0 timm-0.9.16 tomlkit-0.12.0 types-requests-2.31.0.20240406 typing-inspect-0.9.0 uvicorn-0.29.0 watchdog-4.0.0 websockets-11.0.3 zhipuai-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ChatGLM3/finetune_demo && ls && wget https://drive.usercontent.google.com/u/0/uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk&export=download -O AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixs8eGoNr552",
        "outputId": "afc29bc5-ea7b-42e3-af3c-3c608aa09241"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: -O: command not found\n",
            "configs\t\tinference_hf.py      README_en.md  requirements.txt\n",
            "finetune_hf.py\tlora_finetune.ipynb  README.md\n",
            "--2024-04-07 14:16:04--  https://drive.usercontent.google.com/u/0/uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.136.132, 2607:f8b0:4001:c34::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.136.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://drive.usercontent.google.com/uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk [following]\n",
            "--2024-04-07 14:16:04--  https://drive.usercontent.google.com/uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk\n",
            "Reusing existing connection to drive.usercontent.google.com:443.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk [following]\n",
            "--2024-04-07 14:16:04--  https://drive.usercontent.google.com/download?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk\n",
            "Reusing existing connection to drive.usercontent.google.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17069994 (16M) [application/octet-stream]\n",
            "Saving to: ‘uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk’\n",
            "\n",
            "uc?id=13_vf0xRTQsyn 100%[===================>]  16.28M  44.1MB/s    in 0.4s    \n",
            "\n",
            "2024-04-07 14:16:09 (44.1 MB/s) - ‘uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk’ saved [17069994/17069994]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ChatGLM3/finetune_demo && ls && tar -zxvf 'uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk' && echo '---------' && ls -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiqgdpZwsVWq",
        "outputId": "fdb1748f-b6ef-4932-9c78-387d3fc50e08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " configs\t  inference_hf.py       README_en.md   requirements.txt\n",
            " finetune_hf.py   lora_finetune.ipynb   README.md     'uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk'\n",
            "AdvertiseGen/\n",
            "AdvertiseGen/train.json\n",
            "AdvertiseGen/dev.json\n",
            "---------\n",
            " AdvertiseGen\t  inference_hf.py       README.md\n",
            " configs\t  lora_finetune.ipynb   requirements.txt\n",
            " finetune_hf.py   README_en.md\t       'uc?id=13_vf0xRTQsyneRKdD1bZIr93vBGOczrk'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r ChatGLM3/finetune_demo/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMqt8PpftnNt",
        "outputId": "d49d65ec-d4d5-4464-9f79-530aa37d1cc7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m185.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ChatGLM3/finetune_demo && python finetune_hf.py  AdvertiseGen/  THUDM/chatglm3-6b  configs/lora.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjojlI9MtZqf",
        "outputId": "0c22ae35-3f5c-4af1-e1e4-067678edc1e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-07 14:19:22.490848: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 14:19:22.490902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 14:19:22.492779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 14:19:23.558806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "tokenizer_config.json: 100% 1.40k/1.40k [00:00<00:00, 7.99MB/s]\n",
            "tokenization_chatglm.py: 100% 13.0k/13.0k [00:00<00:00, 33.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- tokenization_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "tokenizer.model: 100% 1.02M/1.02M [00:00<00:00, 17.6MB/s]\n",
            "special_tokens_map.json: 100% 3.00/3.00 [00:00<00:00, 12.6kB/s]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "config.json: 100% 1.32k/1.32k [00:00<00:00, 8.09MB/s]\n",
            "configuration_chatglm.py: 100% 2.33k/2.33k [00:00<00:00, 14.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- configuration_chatglm.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "modeling_chatglm.py: 100% 55.9k/55.9k [00:00<00:00, 14.2MB/s]\n",
            "quantization.py: 100% 14.7k/14.7k [00:00<00:00, 41.2MB/s]\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:\n",
            "- modeling_chatglm.py\n",
            "- quantization.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "model.safetensors.index.json: 100% 21.2k/21.2k [00:00<00:00, 78.5MB/s]\n",
            "Downloading shards:   0% 0/7 [00:00<?, ?it/s]\n",
            "model-00001-of-00007.safetensors:   0% 0.00/1.83G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   1% 10.5M/1.83G [00:00<00:27, 66.5MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   2% 31.5M/1.83G [00:00<00:14, 120MB/s] \u001b[A\n",
            "model-00001-of-00007.safetensors:   3% 62.9M/1.83G [00:00<00:10, 166MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   5% 94.4M/1.83G [00:00<00:09, 186MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   6% 115M/1.83G [00:00<00:08, 192MB/s] \u001b[A\n",
            "model-00001-of-00007.safetensors:   8% 147M/1.83G [00:00<00:08, 200MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:   9% 168M/1.83G [00:00<00:08, 202MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  11% 199M/1.83G [00:01<00:07, 205MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  13% 231M/1.83G [00:01<00:07, 207MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  14% 262M/1.83G [00:01<00:07, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  16% 294M/1.83G [00:01<00:07, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  18% 325M/1.83G [00:01<00:07, 211MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  20% 357M/1.83G [00:01<00:06, 211MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  21% 388M/1.83G [00:01<00:06, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  23% 419M/1.83G [00:02<00:06, 209MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  25% 451M/1.83G [00:02<00:06, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  26% 482M/1.83G [00:02<00:06, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  28% 514M/1.83G [00:02<00:06, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  30% 545M/1.83G [00:02<00:06, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  32% 577M/1.83G [00:02<00:05, 211MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  33% 608M/1.83G [00:03<00:05, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  35% 640M/1.83G [00:03<00:05, 211MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  37% 671M/1.83G [00:03<00:05, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  38% 703M/1.83G [00:03<00:05, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  40% 734M/1.83G [00:03<00:05, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  42% 765M/1.83G [00:03<00:05, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  44% 797M/1.83G [00:03<00:04, 209MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  45% 828M/1.83G [00:04<00:04, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  47% 860M/1.83G [00:04<00:04, 208MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  49% 891M/1.83G [00:04<00:04, 209MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  50% 923M/1.83G [00:04<00:04, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  52% 954M/1.83G [00:04<00:04, 214MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  54% 986M/1.83G [00:04<00:03, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  56% 1.02G/1.83G [00:04<00:03, 215MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  57% 1.05G/1.83G [00:05<00:03, 218MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  59% 1.08G/1.83G [00:05<00:03, 219MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  61% 1.11G/1.83G [00:05<00:03, 220MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  63% 1.14G/1.83G [00:05<00:03, 215MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  64% 1.17G/1.83G [00:05<00:03, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  66% 1.21G/1.83G [00:05<00:02, 215MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  68% 1.24G/1.83G [00:05<00:02, 216MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  69% 1.27G/1.83G [00:06<00:02, 219MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  71% 1.30G/1.83G [00:06<00:02, 218MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  73% 1.33G/1.83G [00:06<00:02, 217MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  75% 1.36G/1.83G [00:06<00:02, 216MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  76% 1.39G/1.83G [00:06<00:02, 213MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  78% 1.43G/1.83G [00:06<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  80% 1.46G/1.83G [00:06<00:01, 212MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  81% 1.49G/1.83G [00:07<00:01, 209MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  83% 1.51G/1.83G [00:07<00:01, 208MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  84% 1.53G/1.83G [00:07<00:01, 201MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  85% 1.55G/1.83G [00:07<00:01, 203MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  86% 1.57G/1.83G [00:07<00:01, 204MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  87% 1.59G/1.83G [00:07<00:01, 203MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  88% 1.61G/1.83G [00:07<00:01, 196MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  89% 1.64G/1.83G [00:07<00:00, 192MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  91% 1.66G/1.83G [00:07<00:00, 196MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  92% 1.68G/1.83G [00:08<00:00, 200MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  93% 1.70G/1.83G [00:08<00:00, 201MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  94% 1.72G/1.83G [00:08<00:00, 203MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  95% 1.74G/1.83G [00:08<00:00, 203MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  96% 1.76G/1.83G [00:08<00:00, 204MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  98% 1.78G/1.83G [00:08<00:00, 205MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors:  99% 1.80G/1.83G [00:08<00:00, 205MB/s]\u001b[A\n",
            "model-00001-of-00007.safetensors: 100% 1.83G/1.83G [00:08<00:00, 207MB/s]\n",
            "Downloading shards:  14% 1/7 [00:08<00:53,  8.96s/it]\n",
            "model-00002-of-00007.safetensors:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   1% 10.5M/1.97G [00:00<00:20, 97.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   2% 31.5M/1.97G [00:00<00:15, 127MB/s] \u001b[A\n",
            "model-00002-of-00007.safetensors:   3% 52.4M/1.97G [00:00<00:13, 144MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   4% 73.4M/1.97G [00:00<00:12, 155MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   5% 94.4M/1.97G [00:00<00:11, 168MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   6% 115M/1.97G [00:00<00:10, 178MB/s] \u001b[A\n",
            "model-00002-of-00007.safetensors:   7% 136M/1.97G [00:00<00:10, 182MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:   8% 157M/1.97G [00:00<00:09, 190MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  10% 189M/1.97G [00:01<00:08, 200MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  11% 220M/1.97G [00:01<00:08, 206MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  13% 252M/1.97G [00:01<00:08, 210MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  14% 283M/1.97G [00:01<00:07, 213MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  16% 315M/1.97G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  18% 346M/1.97G [00:01<00:07, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  19% 377M/1.97G [00:01<00:07, 219MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  21% 409M/1.97G [00:02<00:07, 219MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  22% 440M/1.97G [00:02<00:06, 219MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  24% 472M/1.97G [00:02<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  26% 503M/1.97G [00:02<00:06, 220MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  27% 535M/1.97G [00:02<00:06, 217MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  29% 566M/1.97G [00:02<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  30% 598M/1.97G [00:02<00:06, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  32% 629M/1.97G [00:03<00:06, 219MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  34% 661M/1.97G [00:03<00:05, 220MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  35% 692M/1.97G [00:03<00:05, 220MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  37% 724M/1.97G [00:03<00:05, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  38% 755M/1.97G [00:03<00:05, 218MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  40% 786M/1.97G [00:03<00:05, 219MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  42% 818M/1.97G [00:03<00:05, 220MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  43% 849M/1.97G [00:04<00:05, 221MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  45% 881M/1.97G [00:04<00:05, 210MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  46% 912M/1.97G [00:04<00:05, 211MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  48% 944M/1.97G [00:04<00:04, 212MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  50% 975M/1.97G [00:04<00:04, 215MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  51% 1.01G/1.97G [00:04<00:04, 216MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  53% 1.04G/1.97G [00:04<00:04, 213MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  54% 1.07G/1.97G [00:05<00:04, 214MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  56% 1.10G/1.97G [00:05<00:04, 214MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  58% 1.13G/1.97G [00:05<00:03, 213MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  59% 1.16G/1.97G [00:05<00:03, 211MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  61% 1.20G/1.97G [00:05<00:03, 212MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  62% 1.23G/1.97G [00:05<00:03, 211MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  64% 1.26G/1.97G [00:06<00:03, 205MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  66% 1.29G/1.97G [00:06<00:03, 208MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  67% 1.31G/1.97G [00:06<00:03, 208MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  68% 1.33G/1.97G [00:06<00:03, 208MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  69% 1.35G/1.97G [00:06<00:04, 134MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  70% 1.38G/1.97G [00:06<00:04, 129MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  71% 1.41G/1.97G [00:07<00:05, 109MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  72% 1.43G/1.97G [00:07<00:05, 104MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  74% 1.45G/1.97G [00:07<00:05, 92.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  74% 1.46G/1.97G [00:07<00:05, 86.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  75% 1.47G/1.97G [00:08<00:05, 86.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  75% 1.48G/1.97G [00:08<00:05, 88.6MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  76% 1.49G/1.97G [00:08<00:05, 88.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  76% 1.50G/1.97G [00:08<00:05, 88.6MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  77% 1.51G/1.97G [00:08<00:05, 78.5MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  77% 1.52G/1.97G [00:08<00:05, 75.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  78% 1.53G/1.97G [00:08<00:05, 75.7MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  78% 1.54G/1.97G [00:08<00:05, 77.7MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  79% 1.55G/1.97G [00:09<00:05, 73.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  79% 1.56G/1.97G [00:09<00:05, 70.4MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  80% 1.57G/1.97G [00:09<00:05, 69.9MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  80% 1.58G/1.97G [00:09<00:05, 69.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  81% 1.59G/1.97G [00:09<00:05, 65.1MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  82% 1.60G/1.97G [00:09<00:05, 64.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  83% 1.63G/1.97G [00:10<00:04, 73.0MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  83% 1.64G/1.97G [00:10<00:04, 66.8MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  84% 1.65G/1.97G [00:10<00:04, 73.3MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  84% 1.66G/1.97G [00:10<00:04, 71.6MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  86% 1.69G/1.97G [00:10<00:02, 112MB/s] \u001b[A\n",
            "model-00002-of-00007.safetensors:  87% 1.72G/1.97G [00:10<00:01, 143MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  89% 1.75G/1.97G [00:11<00:01, 165MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  91% 1.78G/1.97G [00:11<00:01, 182MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  92% 1.80G/1.97G [00:11<00:00, 188MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  93% 1.82G/1.97G [00:11<00:00, 193MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  94% 1.86G/1.97G [00:11<00:00, 201MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  95% 1.88G/1.97G [00:11<00:00, 203MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  97% 1.91G/1.97G [00:11<00:00, 207MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors:  99% 1.94G/1.97G [00:11<00:00, 213MB/s]\u001b[A\n",
            "model-00002-of-00007.safetensors: 100% 1.97G/1.97G [00:12<00:00, 163MB/s]\n",
            "Downloading shards:  29% 2/7 [00:21<00:54, 10.89s/it]\n",
            "model-00003-of-00007.safetensors:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   1% 10.5M/1.93G [00:00<00:21, 90.4MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   2% 31.5M/1.93G [00:00<00:15, 122MB/s] \u001b[A\n",
            "model-00003-of-00007.safetensors:   3% 52.4M/1.93G [00:00<00:12, 150MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   4% 83.9M/1.93G [00:00<00:10, 179MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   5% 105M/1.93G [00:00<00:09, 188MB/s] \u001b[A\n",
            "model-00003-of-00007.safetensors:   7% 136M/1.93G [00:00<00:09, 198MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:   9% 168M/1.93G [00:00<00:08, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  10% 199M/1.93G [00:01<00:08, 206MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  12% 231M/1.93G [00:01<00:08, 209MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  13% 252M/1.93G [00:01<00:08, 207MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  14% 273M/1.93G [00:01<00:08, 206MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  15% 294M/1.93G [00:01<00:08, 194MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  16% 315M/1.93G [00:01<00:08, 195MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  17% 336M/1.93G [00:01<00:08, 197MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  18% 357M/1.93G [00:01<00:07, 199MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  20% 377M/1.93G [00:01<00:07, 200MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  21% 398M/1.93G [00:02<00:07, 199MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  22% 419M/1.93G [00:02<00:07, 200MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  23% 440M/1.93G [00:02<00:07, 201MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  24% 461M/1.93G [00:02<00:07, 201MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  25% 482M/1.93G [00:02<00:07, 202MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  26% 503M/1.93G [00:02<00:07, 202MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  27% 524M/1.93G [00:02<00:06, 202MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  28% 545M/1.93G [00:02<00:06, 201MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  29% 566M/1.93G [00:02<00:06, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  31% 598M/1.93G [00:03<00:06, 208MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  33% 629M/1.93G [00:03<00:06, 211MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  34% 661M/1.93G [00:03<00:05, 214MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  36% 692M/1.93G [00:03<00:05, 216MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  38% 724M/1.93G [00:03<00:05, 217MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  39% 755M/1.93G [00:03<00:05, 218MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  41% 786M/1.93G [00:03<00:05, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  42% 818M/1.93G [00:04<00:05, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  44% 849M/1.93G [00:04<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  46% 881M/1.93G [00:04<00:04, 218MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  47% 912M/1.93G [00:04<00:04, 221MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  49% 944M/1.93G [00:04<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  51% 975M/1.93G [00:04<00:04, 218MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  52% 1.01G/1.93G [00:04<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  54% 1.04G/1.93G [00:05<00:04, 219MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  55% 1.07G/1.93G [00:05<00:03, 220MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  57% 1.10G/1.93G [00:05<00:05, 151MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  59% 1.13G/1.93G [00:05<00:04, 166MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  60% 1.16G/1.93G [00:05<00:04, 179MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  62% 1.20G/1.93G [00:05<00:03, 189MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  64% 1.23G/1.93G [00:06<00:03, 198MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  65% 1.26G/1.93G [00:06<00:03, 203MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  67% 1.29G/1.93G [00:06<00:03, 207MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  69% 1.32G/1.93G [00:06<00:02, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  70% 1.34G/1.93G [00:06<00:02, 202MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  71% 1.37G/1.93G [00:06<00:02, 206MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  73% 1.41G/1.93G [00:06<00:02, 210MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  75% 1.44G/1.93G [00:07<00:02, 209MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  76% 1.46G/1.93G [00:07<00:02, 209MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  77% 1.49G/1.93G [00:07<00:02, 212MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  79% 1.52G/1.93G [00:07<00:01, 212MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  81% 1.55G/1.93G [00:07<00:01, 212MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  82% 1.58G/1.93G [00:07<00:01, 214MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  84% 1.61G/1.93G [00:07<00:01, 215MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  85% 1.65G/1.93G [00:08<00:01, 214MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  87% 1.68G/1.93G [00:08<00:01, 210MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  89% 1.71G/1.93G [00:08<00:01, 208MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  90% 1.73G/1.93G [00:08<00:00, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  91% 1.75G/1.93G [00:08<00:00, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  92% 1.77G/1.93G [00:08<00:00, 204MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  93% 1.79G/1.93G [00:08<00:00, 206MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  95% 1.82G/1.93G [00:08<00:00, 210MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  96% 1.86G/1.93G [00:09<00:00, 211MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors:  98% 1.89G/1.93G [00:09<00:00, 211MB/s]\u001b[A\n",
            "model-00003-of-00007.safetensors: 100% 1.93G/1.93G [00:09<00:00, 204MB/s]\n",
            "Downloading shards:  43% 3/7 [00:30<00:41, 10.29s/it]\n",
            "model-00004-of-00007.safetensors:   0% 0.00/1.82G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   1% 21.0M/1.82G [00:00<00:11, 150MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   2% 41.9M/1.82G [00:00<00:09, 180MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   4% 73.4M/1.82G [00:00<00:08, 196MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   5% 94.4M/1.82G [00:00<00:08, 193MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:   7% 126M/1.82G [00:00<00:08, 202MB/s] \u001b[A\n",
            "model-00004-of-00007.safetensors:   9% 157M/1.82G [00:00<00:08, 207MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  10% 189M/1.82G [00:00<00:07, 209MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  12% 220M/1.82G [00:01<00:07, 212MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  14% 252M/1.82G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  16% 283M/1.82G [00:01<00:07, 217MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  17% 315M/1.82G [00:01<00:06, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  19% 346M/1.82G [00:01<00:06, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  21% 377M/1.82G [00:01<00:06, 217MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  23% 409M/1.82G [00:01<00:06, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  24% 440M/1.82G [00:02<00:06, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  26% 472M/1.82G [00:02<00:06, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  28% 503M/1.82G [00:02<00:06, 217MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  29% 535M/1.82G [00:02<00:05, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  31% 566M/1.82G [00:02<00:05, 212MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  33% 598M/1.82G [00:02<00:05, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  35% 629M/1.82G [00:02<00:05, 211MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  36% 661M/1.82G [00:03<00:05, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  38% 692M/1.82G [00:03<00:05, 212MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  40% 724M/1.82G [00:03<00:05, 211MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  42% 755M/1.82G [00:03<00:05, 211MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  43% 786M/1.82G [00:03<00:04, 208MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  45% 818M/1.82G [00:03<00:04, 211MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  47% 849M/1.82G [00:04<00:04, 209MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  48% 870M/1.82G [00:04<00:04, 209MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  50% 902M/1.82G [00:04<00:04, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  51% 933M/1.82G [00:04<00:04, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  53% 965M/1.82G [00:04<00:03, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  55% 996M/1.82G [00:04<00:03, 214MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  57% 1.03G/1.82G [00:04<00:03, 216MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  58% 1.06G/1.82G [00:05<00:03, 216MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  60% 1.09G/1.82G [00:05<00:03, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  62% 1.12G/1.82G [00:05<00:03, 217MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  64% 1.15G/1.82G [00:05<00:03, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  65% 1.18G/1.82G [00:05<00:02, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  67% 1.22G/1.82G [00:05<00:02, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  69% 1.25G/1.82G [00:05<00:02, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  70% 1.28G/1.82G [00:06<00:02, 220MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  72% 1.31G/1.82G [00:06<00:02, 220MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  74% 1.34G/1.82G [00:06<00:02, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  76% 1.37G/1.82G [00:06<00:02, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  77% 1.41G/1.82G [00:06<00:01, 216MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  79% 1.44G/1.82G [00:06<00:01, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  81% 1.47G/1.82G [00:06<00:01, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  83% 1.50G/1.82G [00:07<00:01, 217MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  84% 1.53G/1.82G [00:07<00:01, 218MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  86% 1.56G/1.82G [00:07<00:01, 219MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  88% 1.59G/1.82G [00:07<00:01, 211MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  90% 1.63G/1.82G [00:07<00:00, 214MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  91% 1.66G/1.82G [00:07<00:00, 216MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  93% 1.69G/1.82G [00:07<00:00, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  95% 1.72G/1.82G [00:08<00:00, 213MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  96% 1.75G/1.82G [00:08<00:00, 214MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors:  98% 1.78G/1.82G [00:08<00:00, 215MB/s]\u001b[A\n",
            "model-00004-of-00007.safetensors: 100% 1.82G/1.82G [00:08<00:00, 213MB/s]\n",
            "Downloading shards:  57% 4/7 [00:39<00:28,  9.62s/it]\n",
            "model-00005-of-00007.safetensors:   0% 0.00/1.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   1% 21.0M/1.97G [00:00<00:11, 163MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   2% 41.9M/1.97G [00:00<00:10, 186MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   3% 62.9M/1.97G [00:00<00:09, 194MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   4% 83.9M/1.97G [00:00<00:09, 199MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   5% 105M/1.97G [00:00<00:09, 202MB/s] \u001b[A\n",
            "model-00005-of-00007.safetensors:   7% 136M/1.97G [00:00<00:08, 208MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:   9% 168M/1.97G [00:00<00:08, 212MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  10% 199M/1.97G [00:00<00:08, 214MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  12% 231M/1.97G [00:01<00:08, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  13% 262M/1.97G [00:01<00:07, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  15% 294M/1.97G [00:01<00:07, 216MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  17% 325M/1.97G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  18% 357M/1.97G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  20% 388M/1.97G [00:01<00:07, 216MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  21% 419M/1.97G [00:01<00:07, 218MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  23% 451M/1.97G [00:02<00:06, 219MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  25% 482M/1.97G [00:02<00:06, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  26% 514M/1.97G [00:02<00:06, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  28% 545M/1.97G [00:02<00:06, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  29% 577M/1.97G [00:02<00:06, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  31% 608M/1.97G [00:02<00:06, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  32% 640M/1.97G [00:02<00:05, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  34% 671M/1.97G [00:03<00:05, 222MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  36% 703M/1.97G [00:03<00:05, 221MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  37% 734M/1.97G [00:03<00:05, 219MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  39% 765M/1.97G [00:03<00:05, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  40% 797M/1.97G [00:03<00:05, 218MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  42% 828M/1.97G [00:03<00:05, 219MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  44% 860M/1.97G [00:03<00:05, 221MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  45% 891M/1.97G [00:04<00:04, 220MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  47% 923M/1.97G [00:04<00:04, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  48% 954M/1.97G [00:04<00:04, 217MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  50% 986M/1.97G [00:04<00:04, 216MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  52% 1.02G/1.97G [00:04<00:04, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  53% 1.05G/1.97G [00:04<00:04, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  55% 1.08G/1.97G [00:05<00:04, 210MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  56% 1.11G/1.97G [00:05<00:04, 208MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  58% 1.14G/1.97G [00:05<00:03, 210MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  60% 1.17G/1.97G [00:05<00:03, 209MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  61% 1.21G/1.97G [00:05<00:03, 210MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  63% 1.24G/1.97G [00:05<00:03, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  64% 1.27G/1.97G [00:05<00:03, 212MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  66% 1.30G/1.97G [00:06<00:03, 214MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  68% 1.33G/1.97G [00:06<00:02, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  69% 1.36G/1.97G [00:06<00:02, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  71% 1.39G/1.97G [00:06<00:02, 216MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  72% 1.43G/1.97G [00:06<00:02, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  74% 1.46G/1.97G [00:06<00:02, 213MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  76% 1.49G/1.97G [00:06<00:02, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  77% 1.52G/1.97G [00:07<00:02, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  79% 1.55G/1.97G [00:07<00:01, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  80% 1.58G/1.97G [00:07<00:01, 212MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  82% 1.61G/1.97G [00:07<00:01, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  84% 1.65G/1.97G [00:07<00:01, 212MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  85% 1.68G/1.97G [00:07<00:01, 214MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  87% 1.71G/1.97G [00:07<00:01, 214MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  88% 1.74G/1.97G [00:08<00:01, 215MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  90% 1.77G/1.97G [00:08<00:00, 213MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  92% 1.80G/1.97G [00:08<00:00, 214MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  93% 1.84G/1.97G [00:08<00:00, 213MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  95% 1.87G/1.97G [00:08<00:00, 211MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  96% 1.90G/1.97G [00:08<00:00, 209MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors:  98% 1.93G/1.97G [00:09<00:00, 210MB/s]\u001b[A\n",
            "model-00005-of-00007.safetensors: 100% 1.97G/1.97G [00:09<00:00, 214MB/s]\n",
            "Downloading shards:  71% 5/7 [00:48<00:19,  9.51s/it]\n",
            "model-00006-of-00007.safetensors:   0% 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   1% 10.5M/1.93G [00:00<00:21, 90.0MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   2% 31.5M/1.93G [00:00<00:14, 135MB/s] \u001b[A\n",
            "model-00006-of-00007.safetensors:   3% 52.4M/1.93G [00:00<00:11, 157MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   4% 83.9M/1.93G [00:00<00:09, 186MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   6% 115M/1.93G [00:00<00:09, 200MB/s] \u001b[A\n",
            "model-00006-of-00007.safetensors:   7% 136M/1.93G [00:00<00:08, 202MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:   9% 168M/1.93G [00:00<00:08, 207MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  10% 199M/1.93G [00:01<00:08, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  12% 231M/1.93G [00:01<00:07, 214MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  14% 262M/1.93G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  15% 294M/1.93G [00:01<00:07, 218MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  17% 325M/1.93G [00:01<00:07, 217MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  18% 357M/1.93G [00:01<00:07, 215MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  20% 388M/1.93G [00:01<00:07, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  22% 419M/1.93G [00:02<00:07, 212MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  23% 451M/1.93G [00:02<00:09, 162MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  24% 472M/1.93G [00:02<00:08, 166MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  26% 493M/1.93G [00:02<00:08, 174MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  27% 524M/1.93G [00:02<00:07, 185MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  28% 545M/1.93G [00:02<00:07, 190MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  30% 577M/1.93G [00:02<00:06, 198MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  31% 598M/1.93G [00:03<00:06, 200MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  32% 619M/1.93G [00:03<00:06, 201MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  34% 650M/1.93G [00:03<00:06, 204MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  35% 671M/1.93G [00:03<00:06, 205MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  36% 692M/1.93G [00:03<00:06, 205MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  38% 724M/1.93G [00:03<00:05, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  39% 755M/1.93G [00:03<00:05, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  41% 786M/1.93G [00:03<00:05, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  42% 818M/1.93G [00:04<00:05, 215MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  44% 849M/1.93G [00:04<00:04, 217MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  46% 881M/1.93G [00:04<00:04, 218MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  47% 912M/1.93G [00:04<00:04, 217MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  49% 944M/1.93G [00:04<00:04, 215MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  51% 975M/1.93G [00:04<00:04, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  52% 1.01G/1.93G [00:04<00:04, 212MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  54% 1.04G/1.93G [00:05<00:04, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  55% 1.07G/1.93G [00:05<00:04, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  57% 1.10G/1.93G [00:05<00:03, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  59% 1.13G/1.93G [00:05<00:03, 214MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  60% 1.16G/1.93G [00:05<00:03, 206MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  61% 1.18G/1.93G [00:05<00:03, 206MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  63% 1.22G/1.93G [00:05<00:03, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  64% 1.24G/1.93G [00:06<00:03, 208MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  65% 1.26G/1.93G [00:06<00:03, 208MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  66% 1.28G/1.93G [00:06<00:03, 207MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  68% 1.31G/1.93G [00:06<00:02, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  69% 1.33G/1.93G [00:06<00:02, 208MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  71% 1.36G/1.93G [00:06<00:02, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  72% 1.39G/1.93G [00:06<00:02, 212MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  74% 1.43G/1.93G [00:07<00:02, 206MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  76% 1.46G/1.93G [00:07<00:02, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  77% 1.49G/1.93G [00:07<00:02, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  79% 1.52G/1.93G [00:07<00:01, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  81% 1.55G/1.93G [00:07<00:01, 215MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  82% 1.58G/1.93G [00:07<00:01, 216MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  84% 1.61G/1.93G [00:07<00:01, 208MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  85% 1.65G/1.93G [00:08<00:01, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  87% 1.68G/1.93G [00:08<00:01, 213MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  89% 1.71G/1.93G [00:08<00:01, 214MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  90% 1.74G/1.93G [00:08<00:00, 214MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  92% 1.77G/1.93G [00:08<00:00, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  94% 1.80G/1.93G [00:08<00:00, 211MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  95% 1.84G/1.93G [00:08<00:00, 204MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  97% 1.87G/1.93G [00:09<00:00, 208MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors:  98% 1.90G/1.93G [00:09<00:00, 209MB/s]\u001b[A\n",
            "model-00006-of-00007.safetensors: 100% 1.93G/1.93G [00:09<00:00, 205MB/s]\n",
            "Downloading shards:  86% 6/7 [00:58<00:09,  9.50s/it]\n",
            "model-00007-of-00007.safetensors:   0% 0.00/1.05G [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   1% 10.5M/1.05G [00:00<00:12, 82.5MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   3% 31.5M/1.05G [00:00<00:07, 133MB/s] \u001b[A\n",
            "model-00007-of-00007.safetensors:   6% 62.9M/1.05G [00:00<00:05, 177MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:   9% 94.4M/1.05G [00:00<00:04, 196MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  12% 126M/1.05G [00:00<00:04, 205MB/s] \u001b[A\n",
            "model-00007-of-00007.safetensors:  15% 157M/1.05G [00:00<00:04, 211MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  18% 189M/1.05G [00:00<00:04, 215MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  21% 220M/1.05G [00:01<00:03, 215MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  24% 252M/1.05G [00:01<00:03, 215MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  27% 283M/1.05G [00:01<00:03, 215MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  30% 315M/1.05G [00:01<00:03, 213MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  33% 346M/1.05G [00:01<00:03, 210MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  36% 377M/1.05G [00:01<00:03, 211MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  39% 409M/1.05G [00:01<00:03, 213MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  42% 440M/1.05G [00:02<00:02, 214MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  45% 472M/1.05G [00:02<00:02, 216MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  48% 503M/1.05G [00:02<00:02, 218MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  51% 535M/1.05G [00:02<00:02, 218MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  54% 566M/1.05G [00:02<00:02, 218MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  57% 598M/1.05G [00:02<00:02, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  60% 629M/1.05G [00:02<00:01, 221MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  63% 661M/1.05G [00:03<00:01, 219MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  66% 692M/1.05G [00:03<00:01, 219MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  69% 724M/1.05G [00:03<00:01, 218MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  72% 755M/1.05G [00:03<00:01, 218MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  75% 786M/1.05G [00:03<00:01, 219MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  78% 818M/1.05G [00:03<00:01, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  81% 849M/1.05G [00:04<00:00, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  84% 881M/1.05G [00:04<00:00, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  87% 912M/1.05G [00:04<00:00, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  90% 944M/1.05G [00:04<00:00, 220MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  93% 975M/1.05G [00:04<00:00, 217MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors:  96% 1.01G/1.05G [00:04<00:00, 217MB/s]\u001b[A\n",
            "model-00007-of-00007.safetensors: 100% 1.05G/1.05G [00:04<00:00, 213MB/s]\n",
            "Downloading shards: 100% 7/7 [01:03<00:00,  9.03s/it]\n",
            "Loading checkpoint shards: 100% 7/7 [00:03<00:00,  2.08it/s]\n",
            "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
            "--> Model\n",
            "\n",
            "--> model has 1.949696M params\n",
            "\n",
            "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 114599 examples [00:00, 697583.66 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
            "Generating validation split: 1070 examples [00:00, 310882.88 examples/s]\n",
            "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
            "Generating test split: 1070 examples [00:00, 348683.50 examples/s]\n",
            "Map (num_proc=16):   0% 0/114599 [00:00<?, ? examples/s]\n",
            "\u001b[1;91mRemoteTraceback: \u001b[0m\n",
            "\u001b[32m\"\"\u001b[0m\"\n",
            "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n",
            "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/multiprocess/pool.py\"\u001b[0m, line \u001b[1;36m125\u001b[0m, in worker\n",
            "    result = \u001b[1m(\u001b[0m\u001b[3;92mTrue\u001b[0m, \u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m*args, **kwds\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
            "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\"\u001b[0m, line \u001b[1;36m623\u001b[0m, in \n",
            "_write_generator_to_queue\n",
            "    for i, result in \u001b[1;35menumerate\u001b[0m\u001b[1m(\u001b[0m\u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m**kwargs\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m:\n",
            "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\"\u001b[0m, line \u001b[1;36m3482\u001b[0m, in \n",
            "_map_single\n",
            "    batch = \u001b[1;35mapply_function_on_filtered_inputs\u001b[0m\u001b[1m(\u001b[0m\n",
            "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\"\u001b[0m, line \u001b[1;36m3361\u001b[0m, in \n",
            "apply_function_on_filtered_inputs\n",
            "    processed_inputs = \u001b[1;35mfunction\u001b[0m\u001b[1m(\u001b[0m*fn_args, *additional_args, **fn_kwargs\u001b[1m)\u001b[0m\n",
            "  File \u001b[32m\"/content/ChatGLM3/finetune_demo/finetune_hf.py\"\u001b[0m, line \u001b[1;36m282\u001b[0m, in process_batch\n",
            "    batched_conv = batch\u001b[1m[\u001b[0m\u001b[32m'conversations'\u001b[0m\u001b[1m]\u001b[0m\n",
            "  File \u001b[32m\"/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\"\u001b[0m, line \u001b[1;36m270\u001b[0m, in \n",
            "__getitem__\n",
            "    value = self.data\u001b[1m[\u001b[0mkey\u001b[1m]\u001b[0m\n",
            "KeyError: \u001b[32m'conversations'\u001b[0m\n",
            "\u001b[32m\"\"\u001b[0m\"\n",
            "\n",
            "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/ChatGLM3/finetune_demo/\u001b[0m\u001b[1;33mfinetune_hf.py\u001b[0m:\u001b[94m462\u001b[0m in \u001b[92mmain\u001b[0m                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m459 \u001b[0m\u001b[2m│   \u001b[0mtokenizer, model = load_tokenizer_and_model(model_dir, peft_config=ft_config.peft_co   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m460 \u001b[0m\u001b[2m│   \u001b[0mdata_manager = DataManager(data_dir, ft_config.data_config)                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m461 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m462 \u001b[2m│   \u001b[0mtrain_dataset = data_manager.get_dataset(                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m463 \u001b[0m\u001b[2m│   │   \u001b[0mSplit.TRAIN,                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m464 \u001b[0m\u001b[2m│   │   \u001b[0mfunctools.partial(                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m465 \u001b[0m\u001b[2m│   │   │   \u001b[0mprocess_batch,                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/ChatGLM3/finetune_demo/\u001b[0m\u001b[1;33mfinetune_hf.py\u001b[0m:\u001b[94m261\u001b[0m in \u001b[92mget_dataset\u001b[0m                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   │   │   \u001b[0mremove_columns = orig_dataset.column_names                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   │   \u001b[0mremove_columns = \u001b[94mNone\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m261 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m orig_dataset.map(                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   │   \u001b[0mprocess_fn,                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatched=batched,                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   │   \u001b[0mremove_columns=remove_columns,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m593\u001b[0m in \u001b[92mwrapper\u001b[0m                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 590 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 591 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mself\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 592 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 593 \u001b[2m│   │   \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 594 \u001b[0m\u001b[2m│   │   \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 595 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 596 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Remove task templates if a column mapping of the template is no longer val\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m558\u001b[0m in \u001b[92mwrapper\u001b[0m                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 555 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33moutput_all_columns\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m._output_all_columns,                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 556 \u001b[0m\u001b[2m│   │   \u001b[0m}                                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 557 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 558 \u001b[2m│   │   \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 559 \u001b[0m\u001b[2m│   │   \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 560 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# re-apply format to the output\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m3197\u001b[0m in \u001b[92mmap\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3194 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtotal=pbar_total,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3195 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mdesc=(desc \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mMap\u001b[0m\u001b[33m\"\u001b[0m) + \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m (num_proc=\u001b[0m\u001b[33m{\u001b[0mnum_proc\u001b[33m}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m,                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3196 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m) \u001b[94mas\u001b[0m pbar:                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3197 \u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m rank, done, content \u001b[95min\u001b[0m iflatmap_unordered(                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3198 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mpool, Dataset._map_single, kwargs_iterable=kwargs_per_job     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3199 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m):                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3200 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m done:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/utils/\u001b[0m\u001b[1;33mpy_utils.py\u001b[0m:\u001b[94m663\u001b[0m in \u001b[92miflatmap_unordered\u001b[0m     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m660 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m661 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m pool_changed:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m662 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# we get the result in case there's an error to raise\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m663 \u001b[2m│   │   │   │   \u001b[0m[async_result.get(timeout=\u001b[94m0.05\u001b[0m) \u001b[94mfor\u001b[0m async_result \u001b[95min\u001b[0m async_results]         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m664 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/utils/\u001b[0m\u001b[1;33mpy_utils.py\u001b[0m:\u001b[94m663\u001b[0m in \u001b[92m<listcomp>\u001b[0m             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m660 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m661 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m pool_changed:                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m662 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# we get the result in case there's an error to raise\u001b[0m                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m663 \u001b[2m│   │   │   │   \u001b[0m[async_result.get(timeout=\u001b[94m0.05\u001b[0m) \u001b[94mfor\u001b[0m async_result \u001b[95min\u001b[0m async_results]         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m664 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/multiprocess/\u001b[0m\u001b[1;33mpool.py\u001b[0m:\u001b[94m774\u001b[0m in \u001b[92mget\u001b[0m                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m771 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._success:                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m772 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._value                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m773 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m774 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mself\u001b[0m._value                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m775 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m776 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_set\u001b[0m(\u001b[96mself\u001b[0m, i, obj):                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m777 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._success, \u001b[96mself\u001b[0m._value = obj                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/multiprocess/\u001b[0m\u001b[1;33mpool.py\u001b[0m:\u001b[94m125\u001b[0m in \u001b[92mworker\u001b[0m                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0mjob, i, func, args, kwds = task                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m125 \u001b[2m│   │   │   \u001b[0mresult = (\u001b[94mTrue\u001b[0m, func(*args, **kwds))                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m wrap_exception \u001b[95mand\u001b[0m func \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m _helper_reraises_exception:                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   │   │   │   \u001b[0me = ExceptionWithTraceback(e, e.__traceback__)                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/utils/\u001b[0m\u001b[1;33mpy_utils.py\u001b[0m:\u001b[94m623\u001b[0m in                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_write_generator_to_queue\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m620 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m621 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m622 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_write_generator_to_queue\u001b[0m(queue: queue.Queue, func: Callable[..., Iterable[Y]], kwar   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m623 \u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i, result \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(func(**kwargs)):                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m624 \u001b[0m\u001b[2m│   │   \u001b[0mqueue.put(result)                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m625 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m i                                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m626 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m3482\u001b[0m in \u001b[92m_map_single\u001b[0m            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3479 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[96mrange\u001b[0m(*(\u001b[96mslice\u001b[0m(i, i + batch_size).indices(shard.num_rows)))    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3480 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m)  \u001b[2m# Something simpler?\u001b[0m                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3481 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3482 \u001b[2m│   │   │   │   │   │   │   \u001b[0mbatch = apply_function_on_filtered_inputs(                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3483 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mbatch,                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3484 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mindices,                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3485 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mcheck_same_num_examples=\u001b[96mlen\u001b[0m(shard.list_indexes()) > \u001b[94m0\u001b[0m,    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m3361\u001b[0m in                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mapply_function_on_filtered_inputs\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3358 \u001b[0m\u001b[2m│   │   │   │   \u001b[0madditional_args += (effective_indices,)                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3359 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m with_rank:                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3360 \u001b[0m\u001b[2m│   │   │   │   \u001b[0madditional_args += (rank,)                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3361 \u001b[2m│   │   │   \u001b[0mprocessed_inputs = function(*fn_args, *additional_args, **fn_kwargs)          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3362 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(processed_inputs, LazyDict):                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3363 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mprocessed_inputs = {                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m3364 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mk: v \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m processed_inputs.data.items() \u001b[94mif\u001b[0m k \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m processed  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/ChatGLM3/finetune_demo/\u001b[0m\u001b[1;33mfinetune_hf.py\u001b[0m:\u001b[94m282\u001b[0m in \u001b[92mprocess_batch\u001b[0m                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   \u001b[0mmax_output_length: \u001b[96mint\u001b[0m,                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m) -> \u001b[96mdict\u001b[0m[\u001b[96mstr\u001b[0m, \u001b[96mlist\u001b[0m]:                                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   \u001b[0mbatched_tools = batch.get(\u001b[33m'\u001b[0m\u001b[33mtools\u001b[0m\u001b[33m'\u001b[0m, \u001b[94mNone\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m282 \u001b[2m│   \u001b[0mbatched_conv = batch[\u001b[33m'\u001b[0m\u001b[33mconversations\u001b[0m\u001b[33m'\u001b[0m]                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   \u001b[0mbatched_input_ids = []                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   \u001b[0mbatched_labels = []                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/datasets/formatting/\u001b[0m\u001b[1;33mformatting.py\u001b[0m:\u001b[94m270\u001b[0m in \u001b[92m__getitem__\u001b[0m     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.data)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m268 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getitem__\u001b[0m(\u001b[96mself\u001b[0m, key):                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m270 \u001b[2m│   │   \u001b[0mvalue = \u001b[96mself\u001b[0m.data[key]                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m271 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m key \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.keys_to_format:                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m272 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue = \u001b[96mself\u001b[0m.format(key)                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m273 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.data[key] = value                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'conversations'\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 参考\n",
        "- https://github.com/THUDM/ChatGLM3/blob/main/finetune_demo/lora_finetune.ipynb"
      ],
      "metadata": {
        "id": "dpLAnudb9Y11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Union\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _resolve_path(path: Union[str, Path]) -> Path:\n",
        "    return Path(path).expanduser().resolve()\n",
        "\n",
        "\n",
        "def _mkdir(dir_name: Union[str, Path]):\n",
        "    dir_name = _resolve_path(dir_name)\n",
        "    if not dir_name.is_dir():\n",
        "        dir_name.mkdir(parents=True, exist_ok=False)\n",
        "\n",
        "\n",
        "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
        "    def _convert(in_file: Path, out_file: Path):\n",
        "        _mkdir(out_file.parent)\n",
        "        with open(in_file, encoding='utf-8') as fin:\n",
        "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
        "                for line in fin:\n",
        "                    dct = json.loads(line)\n",
        "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
        "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
        "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    data_dir = _resolve_path(data_dir)\n",
        "    save_dir = _resolve_path(save_dir)\n",
        "\n",
        "    train_file = data_dir / 'train.json'\n",
        "    if train_file.is_file():\n",
        "        out_file = save_dir / train_file.relative_to(data_dir)\n",
        "        _convert(train_file, out_file)\n",
        "\n",
        "    dev_file = data_dir / 'dev.json'\n",
        "    if dev_file.is_file():\n",
        "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
        "        _convert(dev_file, out_file)\n",
        "\n",
        "\n",
        "# convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')\n",
        "convert_adgen('/content/ChatGLM3/finetune_demo/AdvertiseGen', '/content/ChatGLM3/finetune_demo/AdvertiseGen_fix')"
      ],
      "metadata": {
        "id": "V3kOgFd99WmR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh  /content/ChatGLM3/finetune_demo/AdvertiseGen_fix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz83fwmP9pAU",
        "outputId": "57ad324d-f0bc-492f-99e4-5d8a6f9c7659"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 59M\n",
            "-rw-r--r-- 1 root root 550K Apr  7 14:30 dev.json\n",
            "-rw-r--r-- 1 root root  58M Apr  7 14:30 train.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd ChatGLM3/finetune_demo && CUDA_VISIBLE_DEVICES=1 python finetune_hf.py  AdvertiseGen_fix/  THUDM/chatglm3-6b  configs/lora.yaml"
      ],
      "metadata": {
        "id": "39cAYHMj-M2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ChatGLM3/finetune_demo && python finetune_hf.py  AdvertiseGen_fix/  THUDM/chatglm3-6b  configs/lora.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mj6_zNUBCPP",
        "outputId": "0c15b4ce-4e6b-4337-f9b5-3488a9719ef3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-07 14:44:21.905758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 14:44:21.905815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 14:44:21.907732: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 14:44:22.989539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "Loading checkpoint shards: 100% 7/7 [00:03<00:00,  2.11it/s]\n",
            "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.031217444255383614\n",
            "--> Model\n",
            "\n",
            "--> model has 1.949696M params\n",
            "\n",
            "train_dataset: Dataset({\n",
            "    features: ['input_ids', 'labels'],\n",
            "    num_rows: 114599\n",
            "})\n",
            "val_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "test_dataset: Dataset({\n",
            "    features: ['input_ids', 'output_ids'],\n",
            "    num_rows: 1070\n",
            "})\n",
            "--> Sanity check\n",
            "           '[gMASK]': 64790 -> -100\n",
            "               'sop': 64792 -> -100\n",
            "          '<|user|>': 64795 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '\\n': 13 -> -100\n",
            "                  '': 30910 -> -100\n",
            "                '类型': 33467 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '版': 55090 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '宽松': 40833 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '风格': 32799 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '性感': 40589 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                '图案': 37505 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                '线条': 37216 -> -100\n",
            "                 '*': 30998 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "                 '型': 54888 -> -100\n",
            "                 '#': 31010 -> -100\n",
            "                 '阔': 56529 -> -100\n",
            "                 '腿': 56158 -> -100\n",
            "                 '裤': 56532 -> -100\n",
            "     '<|assistant|>': 64796 -> -100\n",
            "                  '': 30910 -> 30910\n",
            "                '\\n': 13 -> 13\n",
            "                  '': 30910 -> 30910\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '阔': 56529 -> 56529\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '这': 54551 -> 54551\n",
            "                '两年': 33808 -> 33808\n",
            "                '真的': 32041 -> 32041\n",
            "                 '吸': 55360 -> 55360\n",
            "                 '粉': 55486 -> 55486\n",
            "                '不少': 32138 -> 32138\n",
            "                 '，': 31123 -> 31123\n",
            "                '明星': 32943 -> 32943\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '达': 54880 -> 54880\n",
            "                '人的': 31664 -> 31664\n",
            "                '心头': 46565 -> 46565\n",
            "                 '爱': 54799 -> 54799\n",
            "                 '。': 31155 -> 31155\n",
            "                '毕竟': 33051 -> 33051\n",
            "                 '好': 54591 -> 54591\n",
            "                 '穿': 55432 -> 55432\n",
            "                '时尚': 33481 -> 33481\n",
            "                 '，': 31123 -> 31123\n",
            "                 '谁': 55622 -> 55622\n",
            "                '都能': 32904 -> 32904\n",
            "                 '穿': 55432 -> 55432\n",
            "                 '出': 54557 -> 54557\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '长': 54625 -> 54625\n",
            "                 '2': 30943 -> 30943\n",
            "                 '米': 55055 -> 55055\n",
            "               '的效果': 35590 -> 35590\n",
            "                '宽松': 40833 -> 40833\n",
            "                 '的': 54530 -> 54530\n",
            "                 '裤': 56532 -> 56532\n",
            "                 '腿': 56158 -> 56158\n",
            "                 '，': 31123 -> 31123\n",
            "               '当然是': 48466 -> 48466\n",
            "                 '遮': 57148 -> 57148\n",
            "                 '肉': 55343 -> 55343\n",
            "                 '小': 54603 -> 54603\n",
            "                '能手': 49355 -> 49355\n",
            "                 '啊': 55674 -> 55674\n",
            "                 '。': 31155 -> 31155\n",
            "                '上身': 51605 -> 51605\n",
            "                 '随': 55119 -> 55119\n",
            "                 '性': 54642 -> 54642\n",
            "                '自然': 31799 -> 31799\n",
            "                 '不': 54535 -> 54535\n",
            "                 '拘': 57036 -> 57036\n",
            "                 '束': 55625 -> 55625\n",
            "                 '，': 31123 -> 31123\n",
            "                '面料': 46839 -> 46839\n",
            "                 '亲': 55113 -> 55113\n",
            "                 '肤': 56089 -> 56089\n",
            "                '舒适': 33894 -> 33894\n",
            "                 '贴': 55778 -> 55778\n",
            "                '身体': 31902 -> 31902\n",
            "                 '验': 55017 -> 55017\n",
            "                 '感': 54706 -> 54706\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '棒': 56382 -> 56382\n",
            "                 '哒': 59230 -> 59230\n",
            "                 '。': 31155 -> 31155\n",
            "                 '系': 54712 -> 54712\n",
            "                 '带': 54882 -> 54882\n",
            "                '部分': 31726 -> 31726\n",
            "                '增加': 31917 -> 31917\n",
            "                '设计': 31735 -> 31735\n",
            "                '看点': 45032 -> 45032\n",
            "                 '，': 31123 -> 31123\n",
            "                 '还': 54656 -> 54656\n",
            "                 '让': 54772 -> 54772\n",
            "                '单品': 46539 -> 46539\n",
            "               '的设计': 34481 -> 34481\n",
            "                 '感': 54706 -> 54706\n",
            "                '更强': 43084 -> 43084\n",
            "                 '。': 31155 -> 31155\n",
            "                '腿部': 46799 -> 46799\n",
            "                '线条': 37216 -> 37216\n",
            "                 '若': 55351 -> 55351\n",
            "                 '隐': 55733 -> 55733\n",
            "                 '若': 55351 -> 55351\n",
            "                 '现': 54600 -> 54600\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                '性感': 40589 -> 40589\n",
            "                 '撩': 58521 -> 58521\n",
            "                 '人': 54533 -> 54533\n",
            "                 '。': 31155 -> 31155\n",
            "                '颜色': 33692 -> 33692\n",
            "                 '敲': 57004 -> 57004\n",
            "                '温柔': 34678 -> 34678\n",
            "                 '的': 54530 -> 54530\n",
            "                 '，': 31123 -> 31123\n",
            "                 '与': 54619 -> 54619\n",
            "                '裤子': 44722 -> 44722\n",
            "                '本身': 32754 -> 32754\n",
            "                 '所': 54626 -> 54626\n",
            "                '呈现': 33169 -> 33169\n",
            "               '的风格': 48084 -> 48084\n",
            "                '有点': 33149 -> 33149\n",
            "                 '反': 54955 -> 54955\n",
            "                 '差': 55342 -> 55342\n",
            "                 '萌': 56842 -> 56842\n",
            "                 '。': 31155 -> 31155\n",
            "                  '': 2 -> 2\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running training *****\n",
            "  Num examples = 114,599\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3,000\n",
            "  Number of trainable parameters = 1,949,696\n",
            "{'loss': 4.8281, 'grad_norm': 2.3277125358581543, 'learning_rate': 4.9833333333333336e-05, 'epoch': 0.0}\n",
            "{'loss': 4.5973, 'grad_norm': 3.284451723098755, 'learning_rate': 4.966666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 4.4793, 'grad_norm': 3.096137762069702, 'learning_rate': 4.9500000000000004e-05, 'epoch': 0.0}\n",
            "{'loss': 4.1143, 'grad_norm': 3.4331600666046143, 'learning_rate': 4.933333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 4.1096, 'grad_norm': 2.785783529281616, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8596, 'grad_norm': 3.0073745250701904, 'learning_rate': 4.9e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8324, 'grad_norm': 2.944485664367676, 'learning_rate': 4.883333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 3.7402, 'grad_norm': 3.0484137535095215, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6324, 'grad_norm': 3.3265135288238525, 'learning_rate': 4.85e-05, 'epoch': 0.0}\n",
            "{'loss': 3.716, 'grad_norm': 3.4939239025115967, 'learning_rate': 4.8333333333333334e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6686, 'grad_norm': 3.722635269165039, 'learning_rate': 4.8166666666666674e-05, 'epoch': 0.0}\n",
            "{'loss': 3.8449, 'grad_norm': 3.9695565700531006, 'learning_rate': 4.8e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6115, 'grad_norm': 3.555457830429077, 'learning_rate': 4.7833333333333335e-05, 'epoch': 0.0}\n",
            "{'loss': 3.7283, 'grad_norm': 4.535061359405518, 'learning_rate': 4.766666666666667e-05, 'epoch': 0.0}\n",
            "{'loss': 3.6832, 'grad_norm': 3.760056972503662, 'learning_rate': 4.75e-05, 'epoch': 0.01}\n",
            "{'loss': 3.7437, 'grad_norm': 4.002797603607178, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5732, 'grad_norm': 4.180429935455322, 'learning_rate': 4.716666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5723, 'grad_norm': 4.379851341247559, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5477, 'grad_norm': 4.86271858215332, 'learning_rate': 4.683333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5723, 'grad_norm': 4.5420355796813965, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5479, 'grad_norm': 5.035916328430176, 'learning_rate': 4.6500000000000005e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6426, 'grad_norm': 4.110814094543457, 'learning_rate': 4.633333333333333e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6094, 'grad_norm': 4.78631591796875, 'learning_rate': 4.6166666666666666e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5084, 'grad_norm': 4.576489448547363, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4719, 'grad_norm': 5.469025611877441, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.599, 'grad_norm': 5.404316425323486, 'learning_rate': 4.566666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5465, 'grad_norm': 5.48642635345459, 'learning_rate': 4.55e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6133, 'grad_norm': 4.5796098709106445, 'learning_rate': 4.5333333333333335e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6275, 'grad_norm': 4.834353446960449, 'learning_rate': 4.516666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5377, 'grad_norm': 5.936253547668457, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4654, 'grad_norm': 5.385719299316406, 'learning_rate': 4.483333333333333e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6053, 'grad_norm': 5.807036399841309, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4137, 'grad_norm': 5.302008152008057, 'learning_rate': 4.4500000000000004e-05, 'epoch': 0.01}\n",
            "{'loss': 3.49, 'grad_norm': 5.464818477630615, 'learning_rate': 4.433333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5174, 'grad_norm': 5.556960105895996, 'learning_rate': 4.4166666666666665e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5736, 'grad_norm': 5.220956325531006, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
            "{'loss': 3.3592, 'grad_norm': 4.927412509918213, 'learning_rate': 4.383333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5305, 'grad_norm': 5.235672950744629, 'learning_rate': 4.3666666666666666e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5227, 'grad_norm': 5.325178623199463, 'learning_rate': 4.35e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4717, 'grad_norm': 5.677399635314941, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6854, 'grad_norm': 5.504457950592041, 'learning_rate': 4.316666666666667e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4953, 'grad_norm': 5.097723007202148, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
            "{'loss': 3.6219, 'grad_norm': 5.680039405822754, 'learning_rate': 4.2833333333333335e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4154, 'grad_norm': 6.612025260925293, 'learning_rate': 4.266666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4135, 'grad_norm': 6.1845316886901855, 'learning_rate': 4.25e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4246, 'grad_norm': 5.67529821395874, 'learning_rate': 4.233333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5295, 'grad_norm': 5.933022499084473, 'learning_rate': 4.216666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4475, 'grad_norm': 7.1128082275390625, 'learning_rate': 4.2e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4529, 'grad_norm': 5.825314521789551, 'learning_rate': 4.183333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5605, 'grad_norm': 5.973183631896973, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.02}\n",
            " 17% 500/3000 [01:42<09:26,  4.41it/s]***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.64s/it]\u001b[A\n",
            " 75% 3/4 [00:26<00:08,  8.30s/it]\u001b[A\n",
            "100% 4/4 [00:48<00:00, 13.50s/it]\u001b[ABuilding prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.735 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "                                      \n",
            "\u001b[A{'eval_rouge-1': 31.37568, 'eval_rouge-2': 6.437207999999999, 'eval_rouge-l': 23.404738000000002, 'eval_bleu-4': 0.028657055364219256, 'eval_runtime': 72.7214, 'eval_samples_per_second': 0.688, 'eval_steps_per_second': 0.055, 'epoch': 0.02}\n",
            " 17% 500/3000 [02:55<09:26,  4.41it/s]\n",
            "100% 4/4 [00:49<00:00, 13.50s/it]\u001b[A\n",
            "{'loss': 3.3213, 'grad_norm': 5.81663179397583, 'learning_rate': 4.15e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5439, 'grad_norm': 6.7045063972473145, 'learning_rate': 4.133333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5822, 'grad_norm': 6.036535263061523, 'learning_rate': 4.116666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4846, 'grad_norm': 5.408646106719971, 'learning_rate': 4.1e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5223, 'grad_norm': 5.3805437088012695, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.6437, 'grad_norm': 5.830050945281982, 'learning_rate': 4.066666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4916, 'grad_norm': 5.824333190917969, 'learning_rate': 4.05e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3693, 'grad_norm': 5.598657608032227, 'learning_rate': 4.0333333333333336e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4215, 'grad_norm': 6.251147270202637, 'learning_rate': 4.016666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4871, 'grad_norm': 6.553992748260498, 'learning_rate': 4e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4357, 'grad_norm': 6.34116268157959, 'learning_rate': 3.983333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4562, 'grad_norm': 6.673290729522705, 'learning_rate': 3.966666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4453, 'grad_norm': 5.936790943145752, 'learning_rate': 3.9500000000000005e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4543, 'grad_norm': 6.196743965148926, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5311, 'grad_norm': 5.951613903045654, 'learning_rate': 3.9166666666666665e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4799, 'grad_norm': 6.359210968017578, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5377, 'grad_norm': 6.155248641967773, 'learning_rate': 3.883333333333333e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3027, 'grad_norm': 7.070379257202148, 'learning_rate': 3.866666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3988, 'grad_norm': 6.657448768615723, 'learning_rate': 3.85e-05, 'epoch': 0.02}\n",
            "{'loss': 3.3523, 'grad_norm': 6.256509780883789, 'learning_rate': 3.8333333333333334e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4973, 'grad_norm': 6.970889568328857, 'learning_rate': 3.816666666666667e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5273, 'grad_norm': 6.8103203773498535, 'learning_rate': 3.8e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2469, 'grad_norm': 6.9730143547058105, 'learning_rate': 3.7833333333333336e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5693, 'grad_norm': 5.861131191253662, 'learning_rate': 3.766666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3979, 'grad_norm': 6.494776248931885, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4773, 'grad_norm': 6.1483473777771, 'learning_rate': 3.733333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.6223, 'grad_norm': 6.41179895401001, 'learning_rate': 3.7166666666666664e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4701, 'grad_norm': 6.294177532196045, 'learning_rate': 3.7e-05, 'epoch': 0.03}\n",
            "{'loss': 3.325, 'grad_norm': 6.4927239418029785, 'learning_rate': 3.683333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.55, 'grad_norm': 6.85518741607666, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2906, 'grad_norm': 6.502535820007324, 'learning_rate': 3.65e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3553, 'grad_norm': 6.584575653076172, 'learning_rate': 3.633333333333333e-05, 'epoch': 0.03}\n",
            "{'loss': 3.458, 'grad_norm': 7.241469860076904, 'learning_rate': 3.6166666666666674e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4045, 'grad_norm': 6.431065082550049, 'learning_rate': 3.6e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5059, 'grad_norm': 6.298936367034912, 'learning_rate': 3.5833333333333335e-05, 'epoch': 0.03}\n",
            "{'loss': 3.534, 'grad_norm': 6.34869384765625, 'learning_rate': 3.566666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2922, 'grad_norm': 7.176546573638916, 'learning_rate': 3.55e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4896, 'grad_norm': 6.67033576965332, 'learning_rate': 3.5333333333333336e-05, 'epoch': 0.03}\n",
            "{'loss': 3.448, 'grad_norm': 7.543128967285156, 'learning_rate': 3.516666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2615, 'grad_norm': 8.130927085876465, 'learning_rate': 3.5e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4555, 'grad_norm': 7.939041614532471, 'learning_rate': 3.483333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.417, 'grad_norm': 7.031142234802246, 'learning_rate': 3.466666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4582, 'grad_norm': 7.489391803741455, 'learning_rate': 3.45e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5672, 'grad_norm': 7.37209939956665, 'learning_rate': 3.433333333333333e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3627, 'grad_norm': 6.555543899536133, 'learning_rate': 3.4166666666666666e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4367, 'grad_norm': 7.894262313842773, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.03}\n",
            "{'loss': 3.5344, 'grad_norm': 6.016017913818359, 'learning_rate': 3.3833333333333334e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3203, 'grad_norm': 7.049781799316406, 'learning_rate': 3.366666666666667e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4576, 'grad_norm': 7.341954708099365, 'learning_rate': 3.35e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3961, 'grad_norm': 7.96513032913208, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}\n",
            " 33% 1000/3000 [04:35<06:57,  4.79it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.74s/it]\u001b[A\n",
            " 75% 3/4 [00:06<00:02,  2.42s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 31.787117999999996, 'eval_rouge-2': 6.3796040000000005, 'eval_rouge-l': 25.861176, 'eval_bleu-4': 0.03280086425939037, 'eval_runtime': 12.7484, 'eval_samples_per_second': 3.922, 'eval_steps_per_second': 0.314, 'epoch': 0.03}\n",
            " 33% 1000/3000 [04:48<06:57,  4.79it/s]\n",
            "100% 4/4 [00:08<00:00,  2.21s/it]\u001b[A\n",
            "{'loss': 3.4473, 'grad_norm': 6.953114032745361, 'learning_rate': 3.316666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4527, 'grad_norm': 7.390812397003174, 'learning_rate': 3.3e-05, 'epoch': 0.04}\n",
            "{'loss': 3.6482, 'grad_norm': 8.30019760131836, 'learning_rate': 3.283333333333333e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4037, 'grad_norm': 6.6090989112854, 'learning_rate': 3.266666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3877, 'grad_norm': 8.600078582763672, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3576, 'grad_norm': 7.807039260864258, 'learning_rate': 3.233333333333333e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3893, 'grad_norm': 7.175220012664795, 'learning_rate': 3.2166666666666665e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4621, 'grad_norm': 7.383530139923096, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.04}\n",
            "{'loss': 3.523, 'grad_norm': 7.161157131195068, 'learning_rate': 3.183333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4625, 'grad_norm': 6.614422798156738, 'learning_rate': 3.1666666666666666e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3412, 'grad_norm': 6.903991222381592, 'learning_rate': 3.15e-05, 'epoch': 0.04}\n",
            "{'loss': 3.5238, 'grad_norm': 7.896724700927734, 'learning_rate': 3.1333333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4301, 'grad_norm': 7.364529609680176, 'learning_rate': 3.116666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3564, 'grad_norm': 8.152714729309082, 'learning_rate': 3.1e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3174, 'grad_norm': 7.65073823928833, 'learning_rate': 3.0833333333333335e-05, 'epoch': 0.04}\n",
            "{'loss': 3.359, 'grad_norm': 7.152575969696045, 'learning_rate': 3.066666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4504, 'grad_norm': 6.743711471557617, 'learning_rate': 3.05e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4705, 'grad_norm': 6.475136756896973, 'learning_rate': 3.0333333333333337e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3607, 'grad_norm': 6.641499996185303, 'learning_rate': 3.016666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4092, 'grad_norm': 6.4268269538879395, 'learning_rate': 3e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2467, 'grad_norm': 6.682261943817139, 'learning_rate': 2.9833333333333335e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3387, 'grad_norm': 7.46336030960083, 'learning_rate': 2.9666666666666672e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3799, 'grad_norm': 7.478947639465332, 'learning_rate': 2.95e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3719, 'grad_norm': 7.931241989135742, 'learning_rate': 2.9333333333333336e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4449, 'grad_norm': 6.8288092613220215, 'learning_rate': 2.916666666666667e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2789, 'grad_norm': 7.556999206542969, 'learning_rate': 2.9e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4549, 'grad_norm': 7.223623275756836, 'learning_rate': 2.8833333333333334e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3342, 'grad_norm': 7.428112030029297, 'learning_rate': 2.8666666666666668e-05, 'epoch': 0.04}\n",
            "{'loss': 3.3863, 'grad_norm': 7.073202610015869, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4846, 'grad_norm': 7.425988674163818, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4615, 'grad_norm': 7.0335612297058105, 'learning_rate': 2.816666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4537, 'grad_norm': 6.747371196746826, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3998, 'grad_norm': 10.508917808532715, 'learning_rate': 2.7833333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3021, 'grad_norm': 7.537664413452148, 'learning_rate': 2.7666666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3482, 'grad_norm': 7.506346702575684, 'learning_rate': 2.7500000000000004e-05, 'epoch': 0.05}\n",
            "{'loss': 3.299, 'grad_norm': 8.053804397583008, 'learning_rate': 2.733333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.5111, 'grad_norm': 7.475771903991699, 'learning_rate': 2.716666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3857, 'grad_norm': 7.216265678405762, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3584, 'grad_norm': 7.258006572723389, 'learning_rate': 2.6833333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.418, 'grad_norm': 6.697118759155273, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3467, 'grad_norm': 7.562755107879639, 'learning_rate': 2.6500000000000004e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2652, 'grad_norm': 7.781118869781494, 'learning_rate': 2.633333333333333e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3834, 'grad_norm': 7.763469219207764, 'learning_rate': 2.6166666666666668e-05, 'epoch': 0.05}\n",
            "{'loss': 3.358, 'grad_norm': 7.329310417175293, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2648, 'grad_norm': 6.906184673309326, 'learning_rate': 2.5833333333333336e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3941, 'grad_norm': 7.270720958709717, 'learning_rate': 2.5666666666666666e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4338, 'grad_norm': 9.289580345153809, 'learning_rate': 2.5500000000000003e-05, 'epoch': 0.05}\n",
            "{'loss': 3.2988, 'grad_norm': 6.8510050773620605, 'learning_rate': 2.5333333333333337e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4396, 'grad_norm': 7.527878284454346, 'learning_rate': 2.5166666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4551, 'grad_norm': 6.91829252243042, 'learning_rate': 2.5e-05, 'epoch': 0.05}\n",
            " 50% 1500/3000 [06:28<04:32,  5.51it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.94s/it]\u001b[A\n",
            " 75% 3/4 [00:25<00:09,  9.98s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 31.625032000000004, 'eval_rouge-2': 6.48178, 'eval_rouge-l': 24.920176, 'eval_bleu-4': 0.031546085821557164, 'eval_runtime': 33.2641, 'eval_samples_per_second': 1.503, 'eval_steps_per_second': 0.12, 'epoch': 0.05}\n",
            " 50% 1500/3000 [07:01<04:32,  5.51it/s]\n",
            "100% 4/4 [00:28<00:00,  7.52s/it]\u001b[A\n",
            "{'loss': 3.3432, 'grad_norm': 6.982490539550781, 'learning_rate': 2.4833333333333335e-05, 'epoch': 0.05}\n",
            "{'loss': 3.3885, 'grad_norm': 8.090791702270508, 'learning_rate': 2.466666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4408, 'grad_norm': 8.285969734191895, 'learning_rate': 2.45e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4051, 'grad_norm': 7.183544158935547, 'learning_rate': 2.4333333333333336e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4947, 'grad_norm': 7.411703109741211, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4055, 'grad_norm': 8.412641525268555, 'learning_rate': 2.4e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4646, 'grad_norm': 8.063614845275879, 'learning_rate': 2.3833333333333334e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4348, 'grad_norm': 7.764935493469238, 'learning_rate': 2.3666666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5104, 'grad_norm': 9.348955154418945, 'learning_rate': 2.35e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3887, 'grad_norm': 7.099277496337891, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3641, 'grad_norm': 8.107282638549805, 'learning_rate': 2.3166666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3656, 'grad_norm': 8.682598114013672, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4715, 'grad_norm': 7.399856090545654, 'learning_rate': 2.2833333333333334e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3182, 'grad_norm': 8.074589729309082, 'learning_rate': 2.2666666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3689, 'grad_norm': 7.606011390686035, 'learning_rate': 2.25e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3053, 'grad_norm': 7.150254726409912, 'learning_rate': 2.2333333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4781, 'grad_norm': 8.679120063781738, 'learning_rate': 2.216666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3684, 'grad_norm': 7.228415489196777, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3777, 'grad_norm': 7.4703755378723145, 'learning_rate': 2.1833333333333333e-05, 'epoch': 0.06}\n",
            "{'loss': 3.517, 'grad_norm': 7.048828125, 'learning_rate': 2.1666666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4611, 'grad_norm': 7.281728744506836, 'learning_rate': 2.15e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5027, 'grad_norm': 7.410244464874268, 'learning_rate': 2.1333333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.401, 'grad_norm': 7.516317367553711, 'learning_rate': 2.116666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3977, 'grad_norm': 7.547510623931885, 'learning_rate': 2.1e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4682, 'grad_norm': 7.526177883148193, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4455, 'grad_norm': 7.964829921722412, 'learning_rate': 2.0666666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3584, 'grad_norm': 8.284750938415527, 'learning_rate': 2.05e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3496, 'grad_norm': 8.195902824401855, 'learning_rate': 2.0333333333333334e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3928, 'grad_norm': 8.32867431640625, 'learning_rate': 2.0166666666666668e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3381, 'grad_norm': 7.875971794128418, 'learning_rate': 2e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3762, 'grad_norm': 9.082707405090332, 'learning_rate': 1.9833333333333335e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3426, 'grad_norm': 7.744475841522217, 'learning_rate': 1.9666666666666666e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5816, 'grad_norm': 7.962623596191406, 'learning_rate': 1.9500000000000003e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3455, 'grad_norm': 8.609588623046875, 'learning_rate': 1.9333333333333333e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4965, 'grad_norm': 8.987554550170898, 'learning_rate': 1.9166666666666667e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3756, 'grad_norm': 7.311240196228027, 'learning_rate': 1.9e-05, 'epoch': 0.06}\n",
            "{'loss': 3.3125, 'grad_norm': 8.124469757080078, 'learning_rate': 1.8833333333333335e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3066, 'grad_norm': 7.3876633644104, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4031, 'grad_norm': 7.5125837326049805, 'learning_rate': 1.85e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3701, 'grad_norm': 7.960371017456055, 'learning_rate': 1.8333333333333333e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3943, 'grad_norm': 8.166014671325684, 'learning_rate': 1.8166666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4813, 'grad_norm': 7.482729911804199, 'learning_rate': 1.8e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2781, 'grad_norm': 7.888613224029541, 'learning_rate': 1.7833333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.5, 'grad_norm': 7.732828140258789, 'learning_rate': 1.7666666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3615, 'grad_norm': 6.963234901428223, 'learning_rate': 1.75e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2844, 'grad_norm': 8.83800220489502, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3687, 'grad_norm': 7.795933723449707, 'learning_rate': 1.7166666666666666e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2391, 'grad_norm': 7.778916358947754, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4207, 'grad_norm': 7.391611099243164, 'learning_rate': 1.6833333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4684, 'grad_norm': 8.007729530334473, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.07}\n",
            " 67% 2000/3000 [08:41<03:16,  5.10it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:03<00:03,  1.98s/it]\u001b[A\n",
            " 75% 3/4 [00:25<00:09,  9.97s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 31.363188, 'eval_rouge-2': 7.140824, 'eval_rouge-l': 23.036382, 'eval_bleu-4': 0.03325582062584596, 'eval_runtime': 68.3698, 'eval_samples_per_second': 0.731, 'eval_steps_per_second': 0.059, 'epoch': 0.07}\n",
            " 67% 2000/3000 [09:49<03:16,  5.10it/s]\n",
            "100% 4/4 [00:46<00:00, 14.17s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to ./output/tmp-checkpoint-2000\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/103caa40027ebfd8450289ca2f278eac4ff26405/config.json\n",
            "Model config ChatGLMConfig {\n",
            "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
            "  \"add_bias_linear\": false,\n",
            "  \"add_qkv_bias\": true,\n",
            "  \"apply_query_key_layer_scaling\": true,\n",
            "  \"apply_residual_connection_post_layernorm\": false,\n",
            "  \"architectures\": [\n",
            "    \"ChatGLMModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_softmax_in_fp32\": true,\n",
            "  \"auto_map\": {\n",
            "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
            "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
            "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
            "  },\n",
            "  \"bias_dropout_fusion\": true,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"ffn_hidden_size\": 13696,\n",
            "  \"fp32_residual_connection\": false,\n",
            "  \"hidden_dropout\": 0.0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"kv_channels\": 128,\n",
            "  \"layernorm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"chatglm\",\n",
            "  \"multi_query_attention\": true,\n",
            "  \"multi_query_group_num\": 2,\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_layers\": 28,\n",
            "  \"original_rope\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"padded_vocab_size\": 65024,\n",
            "  \"post_layer_norm\": true,\n",
            "  \"pre_seq_len\": null,\n",
            "  \"prefix_projection\": false,\n",
            "  \"quantization_bit\": 0,\n",
            "  \"rmsnorm\": true,\n",
            "  \"seq_length\": 8192,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"float16\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65024\n",
            "}\n",
            "\n",
            "{'loss': 3.3885, 'grad_norm': 8.850046157836914, 'learning_rate': 1.65e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4971, 'grad_norm': 7.337601661682129, 'learning_rate': 1.6333333333333335e-05, 'epoch': 0.07}\n",
            "{'loss': 3.5564, 'grad_norm': 8.848564147949219, 'learning_rate': 1.6166666666666665e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4906, 'grad_norm': 8.540266036987305, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3705, 'grad_norm': 8.342269897460938, 'learning_rate': 1.5833333333333333e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3268, 'grad_norm': 7.7982497215271, 'learning_rate': 1.5666666666666667e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4451, 'grad_norm': 8.242293357849121, 'learning_rate': 1.55e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4223, 'grad_norm': 8.352923393249512, 'learning_rate': 1.5333333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4375, 'grad_norm': 7.462928771972656, 'learning_rate': 1.5166666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.3559, 'grad_norm': 7.789133071899414, 'learning_rate': 1.5e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2971, 'grad_norm': 7.835447788238525, 'learning_rate': 1.4833333333333336e-05, 'epoch': 0.07}\n",
            "{'loss': 3.584, 'grad_norm': 7.94282865524292, 'learning_rate': 1.4666666666666668e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2541, 'grad_norm': 7.665738582611084, 'learning_rate': 1.45e-05, 'epoch': 0.07}\n",
            "{'loss': 3.36, 'grad_norm': 8.344725608825684, 'learning_rate': 1.4333333333333334e-05, 'epoch': 0.07}\n",
            "{'loss': 3.4041, 'grad_norm': 7.467743873596191, 'learning_rate': 1.4166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.5152, 'grad_norm': 8.153535842895508, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3959, 'grad_norm': 7.0873517990112305, 'learning_rate': 1.3833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4141, 'grad_norm': 7.9589033126831055, 'learning_rate': 1.3666666666666666e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3535, 'grad_norm': 7.709102630615234, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.435, 'grad_norm': 7.548598766326904, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4516, 'grad_norm': 6.913430213928223, 'learning_rate': 1.3166666666666665e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4211, 'grad_norm': 7.822855472564697, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4168, 'grad_norm': 8.210623741149902, 'learning_rate': 1.2833333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3742, 'grad_norm': 8.366259574890137, 'learning_rate': 1.2666666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2412, 'grad_norm': 8.533867835998535, 'learning_rate': 1.25e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3652, 'grad_norm': 7.986590385437012, 'learning_rate': 1.2333333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4287, 'grad_norm': 8.720365524291992, 'learning_rate': 1.2166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4654, 'grad_norm': 7.860230445861816, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
            "{'loss': 3.291, 'grad_norm': 8.481099128723145, 'learning_rate': 1.1833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3555, 'grad_norm': 8.320823669433594, 'learning_rate': 1.1666666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3209, 'grad_norm': 8.538289070129395, 'learning_rate': 1.1500000000000002e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3252, 'grad_norm': 8.620716094970703, 'learning_rate': 1.1333333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3654, 'grad_norm': 9.108325004577637, 'learning_rate': 1.1166666666666668e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3635, 'grad_norm': 7.835288047790527, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2707, 'grad_norm': 8.727992057800293, 'learning_rate': 1.0833333333333334e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3777, 'grad_norm': 8.371390342712402, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3496, 'grad_norm': 7.981163501739502, 'learning_rate': 1.05e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4939, 'grad_norm': 8.726273536682129, 'learning_rate': 1.0333333333333333e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2322, 'grad_norm': 8.641095161437988, 'learning_rate': 1.0166666666666667e-05, 'epoch': 0.08}\n",
            "{'loss': 3.4584, 'grad_norm': 7.849058151245117, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
            "{'loss': 3.452, 'grad_norm': 8.196807861328125, 'learning_rate': 9.833333333333333e-06, 'epoch': 0.08}\n",
            "{'loss': 3.2783, 'grad_norm': 8.042312622070312, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.08}\n",
            "{'loss': 3.368, 'grad_norm': 7.373976230621338, 'learning_rate': 9.5e-06, 'epoch': 0.08}\n",
            "{'loss': 3.3777, 'grad_norm': 8.09322738647461, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2723, 'grad_norm': 7.736108779907227, 'learning_rate': 9.166666666666666e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3123, 'grad_norm': 7.932006359100342, 'learning_rate': 9e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2561, 'grad_norm': 8.896297454833984, 'learning_rate': 8.833333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4367, 'grad_norm': 7.59636926651001, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4713, 'grad_norm': 7.935348987579346, 'learning_rate': 8.500000000000002e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3924, 'grad_norm': 9.774373054504395, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.09}\n",
            " 83% 2500/3000 [11:29<01:37,  5.12it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.68s/it]\u001b[A\n",
            " 75% 3/4 [00:42<00:15, 15.08s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 32.368244, 'eval_rouge-2': 6.809875999999999, 'eval_rouge-l': 23.909900000000004, 'eval_bleu-4': 0.031168784710289943, 'eval_runtime': 68.5025, 'eval_samples_per_second': 0.73, 'eval_steps_per_second': 0.058, 'epoch': 0.09}\n",
            " 83% 2500/3000 [12:37<01:37,  5.12it/s]\n",
            "100% 4/4 [01:04<00:00, 17.34s/it]\u001b[A\n",
            "{'loss': 3.2982, 'grad_norm': 8.548090934753418, 'learning_rate': 8.166666666666668e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3367, 'grad_norm': 9.931844711303711, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2516, 'grad_norm': 8.10332202911377, 'learning_rate': 7.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3953, 'grad_norm': 8.397453308105469, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3914, 'grad_norm': 7.84904146194458, 'learning_rate': 7.5e-06, 'epoch': 0.09}\n",
            "{'loss': 3.407, 'grad_norm': 8.600616455078125, 'learning_rate': 7.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4686, 'grad_norm': 8.111486434936523, 'learning_rate': 7.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4775, 'grad_norm': 8.733180046081543, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3719, 'grad_norm': 8.662067413330078, 'learning_rate': 6.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4766, 'grad_norm': 8.870471954345703, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.359, 'grad_norm': 8.200662612915039, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.09}\n",
            "{'loss': 3.424, 'grad_norm': 7.729390621185303, 'learning_rate': 6.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.5213, 'grad_norm': 7.641571998596191, 'learning_rate': 6.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4443, 'grad_norm': 8.638371467590332, 'learning_rate': 6e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4068, 'grad_norm': 8.185625076293945, 'learning_rate': 5.833333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3514, 'grad_norm': 8.036624908447266, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.41, 'grad_norm': 8.721689224243164, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2701, 'grad_norm': 7.669675350189209, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4752, 'grad_norm': 8.713199615478516, 'learning_rate': 5.166666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.4498, 'grad_norm': 9.107588768005371, 'learning_rate': 5e-06, 'epoch': 0.09}\n",
            "{'loss': 3.427, 'grad_norm': 8.56257438659668, 'learning_rate': 4.833333333333333e-06, 'epoch': 0.09}\n",
            "{'loss': 3.2512, 'grad_norm': 7.73335599899292, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.09}\n",
            "{'loss': 3.3793, 'grad_norm': 8.101400375366211, 'learning_rate': 4.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3877, 'grad_norm': 8.183134078979492, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4572, 'grad_norm': 9.043044090270996, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.398, 'grad_norm': 8.334939956665039, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3486, 'grad_norm': 8.344661712646484, 'learning_rate': 3.833333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2625, 'grad_norm': 8.699736595153809, 'learning_rate': 3.666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2779, 'grad_norm': 8.31027889251709, 'learning_rate': 3.5000000000000004e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2414, 'grad_norm': 7.913788795471191, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4436, 'grad_norm': 7.916985988616943, 'learning_rate': 3.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3766, 'grad_norm': 8.2564058303833, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
            "{'loss': 3.392, 'grad_norm': 8.115445137023926, 'learning_rate': 2.8333333333333335e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4404, 'grad_norm': 9.416447639465332, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.4076, 'grad_norm': 8.701863288879395, 'learning_rate': 2.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3387, 'grad_norm': 8.487239837646484, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3727, 'grad_norm': 8.774358749389648, 'learning_rate': 2.166666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.5084, 'grad_norm': 9.216662406921387, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3025, 'grad_norm': 8.029358863830566, 'learning_rate': 1.8333333333333335e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3309, 'grad_norm': 9.092194557189941, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3061, 'grad_norm': 7.945187568664551, 'learning_rate': 1.5e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2488, 'grad_norm': 7.440783977508545, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3607, 'grad_norm': 9.312810897827148, 'learning_rate': 1.1666666666666668e-06, 'epoch': 0.1}\n",
            "{'loss': 3.2566, 'grad_norm': 8.417613983154297, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}\n",
            "{'loss': 3.3785, 'grad_norm': 8.080557823181152, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.1}\n",
            "{'loss': 3.2086, 'grad_norm': 9.150115966796875, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4496, 'grad_norm': 8.982619285583496, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4285, 'grad_norm': 9.149140357971191, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.1}\n",
            "{'loss': 3.4729, 'grad_norm': 8.186620712280273, 'learning_rate': 1.6666666666666668e-07, 'epoch': 0.1}\n",
            "{'loss': 3.3678, 'grad_norm': 7.8601789474487305, 'learning_rate': 0.0, 'epoch': 0.1}\n",
            "100% 3000/3000 [14:17<00:00,  5.29it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 50\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:21<00:21, 10.60s/it]\u001b[A\n",
            " 75% 3/4 [00:42<00:15, 15.02s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_rouge-1': 31.542558, 'eval_rouge-2': 7.071523999999999, 'eval_rouge-l': 23.997576, 'eval_bleu-4': 0.03146761628863228, 'eval_runtime': 85.6762, 'eval_samples_per_second': 0.584, 'eval_steps_per_second': 0.047, 'epoch': 0.1}\n",
            "100% 3000/3000 [15:43<00:00,  5.29it/s]\n",
            "100% 4/4 [01:03<00:00, 17.33s/it]\u001b[A\n",
            "                                 \u001b[A\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 943.5, 'train_samples_per_second': 12.719, 'train_steps_per_second': 3.18, 'train_loss': 3.4450904947916667, 'epoch': 0.1}\n",
            "100% 3000/3000 [15:43<00:00,  3.18it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Prediction *****\n",
            "  Num examples = 1070\n",
            "  Batch size = 16\n",
            "100% 67/67 [16:56<00:00, 15.17s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/ChatGLM3/finetune_demo && python3 inference_hf.py output/checkpoint-2000 --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og7El3sQGmgK",
        "outputId": "9b838f73-491c-4b7b-c3fa-203caa5d6d96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 7/7 [00:04<00:00,  1.62it/s]\n",
            "Setting eos_token is not supported, use the default one.\n",
            "Setting pad_token is not supported, use the default one.\n",
            "Setting unk_token is not supported, use the default one.\n",
            "2024-04-07 15:21:15.101334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-07 15:21:15.101386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-07 15:21:15.103380: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-07 15:21:16.272753: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "这款连衣裙采用不规则拼接设计，打破传统单一的视觉感，时尚个性的效果。搭配木耳边装饰，增添女性柔美的气质，搭配拉链套头设计，穿脱方便，穿起来不紧绷，不束缚，穿着舒适，又很有个性。百褶的裙摆，飘逸舒适，搭配网纱装饰，增添性感女人味，又不会过于暴露。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PEmpi1CkHrHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuIxPdKaHrKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 适配 cli_demo.py\n",
        "> 直接使用有问题，需要用peft适配"
      ],
      "metadata": {
        "id": "9pyuwJpUHweZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/ChatGLM3/basic_demo && export MODEL_PATH='/content/ChatGLM3/finetune_demo/output/checkpoint-2000' && python cli_demo.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DohrlSxYGpTN",
        "outputId": "4ce910ba-5568-45c3-b2a4-68070cd63b97"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/ChatGLM3/basic_demo/cli_demo.py\", line 8, in <module>\n",
            "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, trust_remote_code=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\", line 782, in from_pretrained\n",
            "    config = AutoConfig.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1111, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 633, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 688, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 369, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: /content/ChatGLM3/finetune_demo/output/checkpoint-2000 does not appear to have a file named config.json. Checkout 'https://huggingface.co//content/ChatGLM3/finetune_demo/output/checkpoint-2000/None' for available files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import platform\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from peft import AutoPeftModelForCausalLM, PeftModelForCausalLM\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    PreTrainedTokenizerFast,\n",
        ")\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Annotated, Union\n",
        "\n",
        "ModelType = Union[PreTrainedModel, PeftModelForCausalLM]\n",
        "TokenizerType = Union[PreTrainedTokenizer, PreTrainedTokenizerFast]\n",
        "\n",
        "MODEL_PATH = os.environ.get('MODEL_PATH', 'THUDM/chatglm3-6b')\n",
        "TOKENIZER_PATH = os.environ.get(\"TOKENIZER_PATH\", MODEL_PATH)\n",
        "\n",
        "def _resolve_path(path: Union[str, Path]) -> Path:\n",
        "    return Path(path).expanduser().resolve()\n",
        "def load_model_and_tokenizer(model_dir: Union[str, Path]) -> tuple[ModelType, TokenizerType]:\n",
        "    model_dir = _resolve_path(model_dir)\n",
        "    if (model_dir / 'adapter_config.json').exists():\n",
        "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "            model_dir, trust_remote_code=True, device_map='auto'\n",
        "        )\n",
        "        tokenizer_dir = model.peft_config['default'].base_model_name_or_path\n",
        "    else:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_dir, trust_remote_code=True, device_map='auto'\n",
        "        )\n",
        "        tokenizer_dir = model_dir\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        tokenizer_dir, trust_remote_code=True\n",
        "    )\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(MODEL_PATH, trust_remote_code=True).eval()\n",
        "# add .quantize(bits=4, device=\"cuda\").cuda() before .eval() to use int4 model\n",
        "# must use cuda to load int4 model\n",
        "\n",
        "os_name = platform.system()\n",
        "clear_command = 'cls' if os_name == 'Windows' else 'clear'\n",
        "stop_stream = False\n",
        "\n",
        "welcome_prompt = \"欢迎使用 ChatGLM3-6B 模型，输入内容即可进行对话，clear 清空对话历史，stop 终止程序\"\n",
        "\n",
        "\n",
        "def build_prompt(history):\n",
        "    prompt = welcome_prompt\n",
        "    for query, response in history:\n",
        "        prompt += f\"\\n\\n用户：{query}\"\n",
        "        prompt += f\"\\n\\nChatGLM3-6B：{response}\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def main():\n",
        "    past_key_values, history = None, []\n",
        "    global stop_stream\n",
        "    print(welcome_prompt)\n",
        "    while True:\n",
        "        query = input(\"\\n用户：\")\n",
        "        if query.strip() == \"stop\":\n",
        "            break\n",
        "        if query.strip() == \"clear\":\n",
        "            past_key_values, history = None, []\n",
        "            os.system(clear_command)\n",
        "            print(welcome_prompt)\n",
        "            continue\n",
        "        print(\"\\nChatGLM：\", end=\"\")\n",
        "        current_length = 0\n",
        "        for response, history, past_key_values in model.stream_chat(tokenizer, query, history=history, top_p=1,\n",
        "                                                                    temperature=0.01,\n",
        "                                                                    past_key_values=past_key_values,\n",
        "                                                                    return_past_key_values=True):\n",
        "            if stop_stream:\n",
        "                stop_stream = False\n",
        "                break\n",
        "            else:\n",
        "                print(response[current_length:], end=\"\", flush=True)\n",
        "                current_length = len(response)\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "49e07a3078194f8f8c2187ceb252788d",
            "f39b9ea7764d4a83bf37adaef3f57097",
            "a141d7762ded4914a49b5b17dff21779",
            "0bbe962f917b45dfb7e045f75e89dec9",
            "2875dac9d4b047d9ba0e66d46ee1aa13",
            "4ae0faead11341b1bcbac938f2dd4736",
            "7df47a181cd04781b0df1c03c7f6b437",
            "fc737d9c8a84486aa1dbb30490536b6b",
            "00a07cdeded442a796966b0c30a043bf",
            "754003296e3e43b8a915cdf36721f029",
            "da9737300f5546a28906a3cf66be2432"
          ]
        },
        "id": "noYQhAxWK_AJ",
        "outputId": "958b0097-f3b8-45d2-e362-4d6a7badf24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.103caa40027ebfd8450289ca2f278eac4ff26405.tokenization_chatglm:Setting eos_token is not supported, use the default one.\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.103caa40027ebfd8450289ca2f278eac4ff26405.tokenization_chatglm:Setting pad_token is not supported, use the default one.\n",
            "WARNING:transformers_modules.THUDM.chatglm3-6b.103caa40027ebfd8450289ca2f278eac4ff26405.tokenization_chatglm:Setting unk_token is not supported, use the default one.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49e07a3078194f8f8c2187ceb252788d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "欢迎使用 ChatGLM3-6B 模型，输入内容即可进行对话，clear 清空对话历史，stop 终止程序\n",
            "\n",
            "用户：你好\n",
            "\n",
            "ChatGLM：你好👋！我是"
          ]
        }
      ]
    }
  ]
}