{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_D9kG_efts3"
   },
   "source": [
    "# Transformers 模型量化技术：AWQ（OPT-2.7B）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE9IhcVyktah"
   },
   "source": [
    "![img](https://huggingface.co/datasets/ybelkada/documentation-images/resolve/main/Thumbnail.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwsg6nCwoThm"
   },
   "source": [
    "在2023年6月，Ji Lin等人发表了论文 [AWQ：Activation-aware Weight Quantization for LLM Compression and Acceleration](https://arxiv.org/pdf/2306.00978.pdf)。\n",
    "\n",
    "这篇论文详细介绍了一种激活感知权重量化算法，可以用于压缩任何基于 Transformer 的语言模型，同时只有微小的性能下降。关于 AWQ 算法的详细介绍，见[MIT Han Song 教授分享](https://hanlab.mit.edu/projects/awq)。\n",
    "\n",
    "transformers 现在支持两个不同的 AWQ 开源实现库：\n",
    "\n",
    "- [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)\n",
    "- [LLM-AWQ](https://github.com/mit-han-lab/llm-awq) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H2019RkoiM-"
   },
   "source": [
    "因为 LLM-AWQ 不支持 Nvidia T4 GPU（课程演示 GPU），所以我们使用 AutoAWQ 库来介绍和演示 AWQ 模型量化技术。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dJJRQ2p7eLQ"
   },
   "source": [
    "## 使用 AutoAWQ 量化模型\n",
    "\n",
    "下面我们以 `facebook opt-2.7B` 模型为例，使用 `AutoAWQ` 库实现的 AWQ 算法实现模型量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name_or_path = \"facebook/opt-2.7b\"\n",
    "quant_model_dir = \"models/opt-2.7b-awq\"\n",
    "\n",
    "quant_config = {\n",
    "    \"zero_point\": True,\n",
    "    \"q_group_size\": 128,\n",
    "    \"w_bit\": 4,\n",
    "    \"version\": \"GEMM\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379a0bba9ee74953b5e1facf448da666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载模型\n",
    "model = AutoAWQForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Please pip install zstandard",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# pip install zstandard\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[0;32m----> 3\u001B[0m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmit-han-lab/pile-val-backup\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/load.py:2582\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2579\u001B[0m try_from_hf_gcs \u001B[38;5;241m=\u001B[39m path \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m _PACKAGED_DATASETS_MODULES\n\u001B[1;32m   2581\u001B[0m \u001B[38;5;66;03m# Download and prepare data\u001B[39;00m\n\u001B[0;32m-> 2582\u001B[0m \u001B[43mbuilder_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2583\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2584\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2585\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2586\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtry_from_hf_gcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtry_from_hf_gcs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2587\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2588\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2589\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2591\u001B[0m \u001B[38;5;66;03m# Build dataset for splits\u001B[39;00m\n\u001B[1;32m   2592\u001B[0m keep_in_memory \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2593\u001B[0m     keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(builder_instance\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size)\n\u001B[1;32m   2594\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/builder.py:1005\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001B[0m\n\u001B[1;32m   1003\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1004\u001B[0m         prepare_split_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_proc\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_proc\n\u001B[0;32m-> 1005\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1006\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1007\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1008\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mprepare_split_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1009\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1010\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1011\u001B[0m \u001B[38;5;66;03m# Sync info\u001B[39;00m\n\u001B[1;32m   1012\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(split\u001B[38;5;241m.\u001B[39mnum_bytes \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39msplits\u001B[38;5;241m.\u001B[39mvalues())\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/builder.py:1078\u001B[0m, in \u001B[0;36mDatasetBuilder._download_and_prepare\u001B[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001B[0m\n\u001B[1;32m   1076\u001B[0m split_dict \u001B[38;5;241m=\u001B[39m SplitDict(dataset_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_name)\n\u001B[1;32m   1077\u001B[0m split_generators_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001B[0;32m-> 1078\u001B[0m split_generators \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_split_generators\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msplit_generators_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[38;5;66;03m# Checksums verification\u001B[39;00m\n\u001B[1;32m   1081\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verification_mode \u001B[38;5;241m==\u001B[39m VerificationMode\u001B[38;5;241m.\u001B[39mALL_CHECKS \u001B[38;5;129;01mand\u001B[39;00m dl_manager\u001B[38;5;241m.\u001B[39mrecord_checksums:\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/packaged_modules/json/json.py:51\u001B[0m, in \u001B[0;36mJson._split_generators\u001B[0;34m(self, dl_manager)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdata_files:\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAt least one data file must be specified, but got data_files=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mdata_files\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 51\u001B[0m data_files \u001B[38;5;241m=\u001B[39m \u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_extract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_files\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_files, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m     53\u001B[0m     files \u001B[38;5;241m=\u001B[39m data_files\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/download/download_manager.py:570\u001B[0m, in \u001B[0;36mDownloadManager.download_and_extract\u001B[0;34m(self, url_or_urls)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_and_extract\u001B[39m(\u001B[38;5;28mself\u001B[39m, url_or_urls):\n\u001B[1;32m    555\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Download and extract given `url_or_urls`.\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \n\u001B[1;32m    557\u001B[0m \u001B[38;5;124;03m    Is roughly equivalent to:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;124;03m        extracted_path(s): `str`, extracted paths of given URL(s).\u001B[39;00m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 570\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl_or_urls\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/download/download_manager.py:543\u001B[0m, in \u001B[0;36mDownloadManager.extract\u001B[0;34m(self, path_or_paths, num_proc)\u001B[0m\n\u001B[1;32m    541\u001B[0m download_config\u001B[38;5;241m.\u001B[39mextract_compressed_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    542\u001B[0m extract_func \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_download, download_config\u001B[38;5;241m=\u001B[39mdownload_config)\n\u001B[0;32m--> 543\u001B[0m extracted_paths \u001B[38;5;241m=\u001B[39m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    544\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextract_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mExtracting data files\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m path_or_paths \u001B[38;5;241m=\u001B[39m NestedDataStructure(path_or_paths)\n\u001B[1;32m    550\u001B[0m extracted_paths \u001B[38;5;241m=\u001B[39m NestedDataStructure(extracted_paths)\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/py_utils.py:475\u001B[0m, in \u001B[0;36mmap_nested\u001B[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001B[0m\n\u001B[1;32m    464\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    465\u001B[0m         map_nested(\n\u001B[1;32m    466\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m    473\u001B[0m     ]\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m num_proc \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m num_proc \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m<\u001B[39m parallel_min_length:\n\u001B[0;32m--> 475\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    476\u001B[0m         _single_map_nested((function, obj, types, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm, desc\u001B[38;5;241m=\u001B[39mdesc)\n\u001B[1;32m    478\u001B[0m     ]\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/py_utils.py:476\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    464\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    465\u001B[0m         map_nested(\n\u001B[1;32m    466\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    472\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m    473\u001B[0m     ]\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m num_proc \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m num_proc \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m<\u001B[39m parallel_min_length:\n\u001B[1;32m    475\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m--> 476\u001B[0m         \u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    477\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm, desc\u001B[38;5;241m=\u001B[39mdesc)\n\u001B[1;32m    478\u001B[0m     ]\n\u001B[1;32m    479\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/py_utils.py:385\u001B[0m, in \u001B[0;36m_single_map_nested\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {k: _single_map_nested((function, v, types, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m pbar}\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 385\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [_single_map_nested((function, v, types, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m pbar]\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    387\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mapped\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/py_utils.py:385\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {k: _single_map_nested((function, v, types, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m pbar}\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 385\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [\u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m pbar]\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m    387\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mapped\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/py_utils.py:368\u001B[0m, in \u001B[0;36m_single_map_nested\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;66;03m# Singleton first to spare some computation\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, types):\n\u001B[0;32m--> 368\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rank \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mget_verbosity() \u001B[38;5;241m<\u001B[39m logging\u001B[38;5;241m.\u001B[39mWARNING:\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/download/download_manager.py:459\u001B[0m, in \u001B[0;36mDownloadManager._download\u001B[0;34m(self, url_or_filename, download_config)\u001B[0m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_relative_path(url_or_filename):\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;66;03m# append the relative path to the base_path\u001B[39;00m\n\u001B[1;32m    458\u001B[0m     url_or_filename \u001B[38;5;241m=\u001B[39m url_or_path_join(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_base_path, url_or_filename)\n\u001B[0;32m--> 459\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mcached_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl_or_filename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m out \u001B[38;5;241m=\u001B[39m tracked_str(out)\n\u001B[1;32m    461\u001B[0m out\u001B[38;5;241m.\u001B[39mset_origin(url_or_filename)\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/file_utils.py:219\u001B[0m, in \u001B[0;36mcached_path\u001B[0;34m(url_or_filename, download_config, **download_kwargs)\u001B[0m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output_path\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download_config\u001B[38;5;241m.\u001B[39mextract_compressed_file:\n\u001B[0;32m--> 219\u001B[0m     output_path \u001B[38;5;241m=\u001B[39m \u001B[43mExtractManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_extract\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforce_extract\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m relative_to_absolute_path(output_path)\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/extract.py:48\u001B[0m, in \u001B[0;36mExtractManager.extract\u001B[0;34m(self, input_path, force_extract)\u001B[0m\n\u001B[1;32m     46\u001B[0m output_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_output_path(input_path)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_extract(output_path, force_extract):\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextractor_format\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output_path\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/extract.py:342\u001B[0m, in \u001B[0;36mExtractor.extract\u001B[0;34m(cls, input_path, output_path, extractor_format, extractor)\u001B[0m\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    341\u001B[0m         extractor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mextractors[extractor_format]\n\u001B[0;32m--> 342\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mextractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    344\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    345\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mextractor_format\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m was made required in version 2.4.0 and not passing it will raise an \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    346\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexception in 3.0.0.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    347\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    348\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/peft/lib/python3.10/site-packages/datasets/utils/extract.py:223\u001B[0m, in \u001B[0;36mZstdExtractor.extract\u001B[0;34m(input_path, output_path)\u001B[0m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextract\u001B[39m(input_path: Union[Path, \u001B[38;5;28mstr\u001B[39m], output_path: Union[Path, \u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39mZSTANDARD_AVAILABLE:\n\u001B[0;32m--> 223\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease pip install zstandard\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mzstandard\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mzstd\u001B[39;00m\n\u001B[1;32m    226\u001B[0m     dctx \u001B[38;5;241m=\u001B[39m zstd\u001B[38;5;241m.\u001B[39mZstdDecompressor()\n",
      "\u001B[0;31mImportError\u001B[0m: Please pip install zstandard"
     ]
    }
   ],
   "source": [
    "# pip install zstandard\n",
    "from datasets import load_dataset\n",
    "load_dataset(\"mit-han-lab/pile-val-backup\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T12:54:49.478796Z",
     "start_time": "2024-04-07T12:54:41.629735Z"
    }
   },
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qn_P_E5p7gAN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n",
      "AWQ: 100%|██████████| 32/32 [16:38<00:00, 31.21s/it]\n"
     ]
    }
   ],
   "source": [
    "# 量化模型\n",
    "model.quantize(tokenizer, quant_config=quant_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实测 AWQ 量化模型：GPU显存占用峰值超过10GB\n",
    "\n",
    "\n",
    "```shell\n",
    "Sun Dec 24 15:21:35 2023\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
    "|-----------------------------------------+----------------------+----------------------+\n",
    "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                                         |                      |               MIG M. |\n",
    "|=========================================+======================+======================|\n",
    "|   0  Tesla T4                       Off | 00000000:00:0D.0 Off |                    0 |\n",
    "| N/A   53C    P0              71W /  70W |   7261MiB / 15360MiB |     97%      Default |\n",
    "|                                         |                      |                  N/A |\n",
    "+-----------------------------------------+----------------------+----------------------+\n",
    "\n",
    "+---------------------------------------------------------------------------------------+\n",
    "| Processes:                                                                            |\n",
    "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
    "|        ID   ID                                                             Usage      |\n",
    "|=======================================================================================|```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nVzKDBlP_6MV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero_point': True, 'q_group_size': 128, 'w_bit': 4, 'version': 'GEMM'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuPLq9sa8EaN"
   },
   "source": [
    "#### Transformers 兼容性配置\n",
    "\n",
    "为了使`quant_config` 与 transformers 兼容，我们需要修改配置文件：`使用 Transformers.AwqConfig 来实例化量化模型配置`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KE8xjwlL8DnA"
   },
   "outputs": [],
   "source": [
    "from transformers import AwqConfig, AutoConfig\n",
    "\n",
    "# 修改配置文件以使其与transformers集成兼容\n",
    "quantization_config = AwqConfig(\n",
    "    bits=quant_config[\"w_bit\"],\n",
    "    group_size=quant_config[\"q_group_size\"],\n",
    "    zero_point=quant_config[\"zero_point\"],\n",
    "    version=quant_config[\"version\"].lower(),\n",
    ").to_dict()\n",
    "\n",
    "# 预训练的transformers模型存储在model属性中，我们需要传递一个字典\n",
    "model.model.config.quantization_config = quantization_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models/opt-2.7b-awq/tokenizer_config.json',\n",
       " 'models/opt-2.7b-awq/special_tokens_map.json',\n",
       " 'models/opt-2.7b-awq/vocab.json',\n",
       " 'models/opt-2.7b-awq/merges.txt',\n",
       " 'models/opt-2.7b-awq/added_tokens.json',\n",
       " 'models/opt-2.7b-awq/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型权重\n",
    "model.save_quantized(quant_model_dir)\n",
    "# 保存分词器\n",
    "tokenizer.save_pretrained(quant_model_dir)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptAWQForCausalLM(\n",
       "  (model): OPTForCausalLM(\n",
       "    (model): OPTModel(\n",
       "      (decoder): OPTDecoder(\n",
       "        (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
       "        (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
       "        (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x OPTDecoderLayer(\n",
       "            (self_attn): OPTAttention(\n",
       "              (k_proj): WQLinear_GEMM(in_features=2560, out_features=2560, bias=True, w_bit=4, group_size=128)\n",
       "              (v_proj): WQLinear_GEMM(in_features=2560, out_features=2560, bias=True, w_bit=4, group_size=128)\n",
       "              (q_proj): WQLinear_GEMM(in_features=2560, out_features=2560, bias=True, w_bit=4, group_size=128)\n",
       "              (out_proj): WQLinear_GEMM(in_features=2560, out_features=2560, bias=True, w_bit=4, group_size=128)\n",
       "            )\n",
       "            (activation_fn): ReLU()\n",
       "            (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): WQLinear_GEMM(in_features=2560, out_features=10240, bias=True, w_bit=4, group_size=128)\n",
       "            (fc2): WQLinear_GEMM(in_features=10240, out_features=2560, bias=True, w_bit=4, group_size=128)\n",
       "            (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=2560, out_features=50272, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 GPU 加载量化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(quant_model_dir, device_map=\"cuda\").to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
    "\n",
    "    out = model.generate(**inputs, max_new_tokens=64)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merry Christmas! I'm glad to. M-M-M-M-M-M-M-M-M-M-M- M-M-M-M-1-\n",
      "\n",
      "M-M-M-M-M-M-M-M-M-M-M-M-M-M-M\n"
     ]
    }
   ],
   "source": [
    "result = generate_text(\"Merry Christmas! I'm glad to\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Z0hAXYanCDW3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The woman worked as a the the woman.\n",
      "The the man\n",
      "the the the the the woman\n"
     ]
    }
   ],
   "source": [
    "result = generate_text(\"The woman worked as a\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
